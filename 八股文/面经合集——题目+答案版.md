# 面经合集——题目+答案版

> 注：答案放的是比较精简的版本，更为详细的介绍在其他的笔记里应该有所整理。精简版本有助于回顾核心知识，确保答案能够快速说中重点。



# C++ 篇

## **【1】C++类的存储相关**

可参考链接：（[C++类的存储及类对象内存结构_c++对象的存储空间-CSDN博客](https://blog.csdn.net/fenxinzi557/article/details/51995911)）

> 这道题目考察的是C++中类是怎么存储的，答题的时候考虑一下几个方面：
>
> - 类的数据成员存储参考类的内存对齐（也是结构体的内存对齐），类内函数（非虚函数）存在代码区，虚函数表一般也存储在代码区。静态函数以及静态成员函数都存储在代码区，类的静态成员变量存储在静态区，也因此需要外部初始化。
> - 在C++中，类的声明（即定义类本身）不会占用任何内存分区。只有在声明类的对象时，才会根据写的代码分配到堆区（或者严谨一点说自由存储区）/栈区；
> - 对于基类，如果有虚函数，那么先存放虚函数表指针，然后存放自己的数据成员；如果没有虚函数，那么直接存放数据成员。
> - 对于单一继承的类对象，先存放父类的数据拷贝(包括虚函数表指针)，然后是本类的数据。
> - 虚函数表中，先存放父类的虚函数，再存放子类的虚函数；如果子类重写了父类的某些虚函数，那么新的虚函数会将虚函数表中父类的这些虚函数覆盖。
> - 对于多重继承，先存放第一个父类的数据拷贝，在存放第二个父类的数据拷贝，一次类推，最后存放自己的数据成员。其中每一个父类拷贝都包含一个虚函数表指针。如果子类重载了某个父类的某个虚函数，那么该将该父类虚函数表的函数覆盖。另外，子类自己的虚函数，存储于第一个父类的虚函数表后边部分。
>
> 另外还有一些问题，**比如派生类出现基类中的同名变量后，内存是如何布局的？优先级比较低，有时间或者问到了再来整理吧。虚继承的问题也放到后面单独整理吧。**



## **【2】虚函数表的存储位置和调用逻辑。**

> 1.虚函数表的存储位置一般是在代码区。
>
> 2.调用逻辑是在多态的时候，会查询对象的虚函数表，找到对应的函数并调用。这里就可以延申提一下虚函数表，虚表指针，运行时多态的概念。
>
> 注：虚表指针通常存储在对象的内存布局中，即它作为对象的一部分存在于堆或栈上。每当创建一个具有虚函数的类的对象时，编译器会在该对象的内存结构中添加一个指向虚表的指针。



## **【3】C++内存分区都是什么？**

> 可以参考的链接：[【C++】内存五大区详解_c++内存分区-CSDN博客](https://blog.csdn.net/luhaoran814/article/details/136108790)（有些可以借鉴，但答案主要按下面答就好），一般在答的时候按照下面逻辑即可：
>
> - 栈区：主要存储函数运行时而分配的局部变量，函数参数，返回数据，返回地址,`指针`，`const局部变量`等。**栈区向地址减小的方向增长。**在执行函数时，函数内部变量的存储在栈上。函数执行结束时，系统自动回收。
> - 堆区：**堆区向地址增大的方向增长**，这个区域是在`运行时`使用的，**由`程序员`分配和释放内存**，程序结束时操作系统会对其进行回收，（程序员分配内存像malloc、free、new、delete）一般都是在这个区域进行的；
> - 代码区：又被称为`文本段`。主要存储程序指令、`代码`。代码段中存放`函数`（类的成员函数和全局函数）编译后的可执行的二进制代码，并且这个区域是`只读`区域；
> - 全局区：全局区包含了全局变量、静态变量、常量以及字符串常量。这部分内存在程序结束后由操作系统释放。全局变量和静态变量在编译阶段就已经确定了大小，并且在程序的整个生命周期内都不会被释放。
>   - 如果是问**五大分区**，**则这部分可以变为“常量区”和“全局/静态区”**。针对常量来说，字面值常量（比如`"Hello"`存在常量区；全局/静态const变量存在全局/静态区；局部const变量存在栈或寄存器，可能会被优化掉；`constexpr`常量会在编译时做替换；类的`const static`成员变量存在全局/静态区；动态分配的`const`类对象则可能在堆区。）



## 【4】enum class 的好处/和enum相比较

> 可以参考的链接：[C++新特性——枚举类（enum class），以及与传统枚举的区别_c++的class enum是什么类型-CSDN博客](https://blog.csdn.net/2302_80272644/article/details/141310484)
>
> 传统的 enum 定义在 C++ 中是这样的：
>
> ```c++
> enum TraversalType {
>     Preorder,
>     Inorder,
>     Postorder
> };
> ```
>
> 在这种情况下，Preorder、Inorder 和 Postorder 都是全局作用域中的常量，可以直接使用 Preorder 来引用。如果不同的 enum 类型中有相同名字的枚举值，就会产生冲突。例如，如果你在另一个地方定义了相同名称的 enum，就可能会有名字冲突问题。
>
> **而enum class 解决了传统 enum 的一些问题，主要是：**
>
> - 作用域：enum class 中定义的枚举值不再是全局作用域，而是属于枚举类的作用域。要引用时，需要使用枚举类型名作为前缀。
> - 强类型检查：enum class 是强类型的，不能隐式转换为整数，也不能与整数直接比较。这增加了类型安全性。
>
> 在使用`enum class`的时候，使用方法为：
>
> ```c++
> enum class TraversalType {
>     Preorder,
>     Inorder,
>     Postorder
> };
> //使用方法：if (type == TraversalType::Preorder)
> ```



## 【5】vector怎么实现的，一定都要开辟再拷贝嘛？能不能在原来基础上开辟呢？

> （1）`vector`的实现方法：主要回答动态数组，可以答`begin`，`end`，`end_of_storage`这三个数组，以及扩容的基本机制（每次满了扩容，一般编译器扩2倍）。
>
> （2）通常来说，`vector`的扩容机制如下：
>
> - **开辟新的内存**：分配一块比当前容量更大的新内存（通常是原来容量的两倍）。
> - **拷贝现有元素**：将现有的元素从旧内存拷贝到新内存中。这里可以提一下如果实现了`noexcept`的移动构造函数，会倾向于使用移动语义；
> - **释放旧内存**：释放原来的内存。
>
> `std::vector` 设计时考虑了动态数组的灵活性，通常来说，它并不能在原有内存基础上直接扩展，因为这可能会导致内存碎片或其他复杂性。然而，`std::vector` 可以通过预留空间 (`reserve`) 来优化性能，避免频繁的内存分配和拷贝。
>
> （3）在默认实现中，是不具备在原有内存基础上直接扩展的能力的，会造成**内存碎片等问题。**这里也可以提一下**C++ STL**中Allocator的机制。



## 【6】map和unordered_map区别。哈希表中的value是如何存储的？

> （1）重点回答内容：
>
> - `map`底层是红黑树，而`unordered_map`则使用哈希表；
> - `map`保持元素有序（元素按键排序），而`unordered_map`是无序的；
> - `map`的查找、插入和删除操作的平均时间复杂度为 O(log n)，而`std::unordered_map`：查找、插入和删除操作的平均时间复杂度为 O(1)。
>
> （2）答一下开放寻址法（也可能平方寻址之类的）和链地址法即可。一般用的是链地址法。



## 【7】简述红黑树，为什么不用AVL树而用红黑树

> - （1）红黑树：
>   - 1）每个结点非红即黑；
>   - 2）根节点是黑的；
>   - 3）如果一个结点是红色的，那么它的子节点就是黑色的（也就是不能出现连续的红节点）；
>   - 4）任一结点到树尾端（NULL）的路径上含有的黑色结点个数必须相同。**通过以上定义的限制，红黑树确保没有一条路径会比其他路径多出两倍以上；**因此，红黑树是一种弱平衡二叉树，**相对于严格要求平衡的平衡二叉树来说，它的旋转次数少，所以对于插入、删除操作较多的情况下，通常使用红黑树。**
>   - 5）叶子节点一定是黑的（NIL）
> - （2）使用红黑树不使用AVL的理由：AVL 树是高度平衡的，**频繁的插入和删除，会引起频繁的rebalance（旋转操作），导致效率下降；**红黑树不是高度平衡的，算是一种折中，插入最多两次旋转，删除最多三次旋转，但是执行速度很快。



### （1）为什么红黑树插入删除效率高？为什么红黑树插入删除后迭代器没有失效？

- **红黑树只是做到了近似平衡，并不是严格的平衡，所以在维护平衡的成本上，要比AVL 树要低**。 所以，红黑树的插入、删除、查找各种操作性能都比较稳定。
  - 红黑树的最长链和最短链之间的长度差不会超过两倍。
- 关于迭代器失效问题，可以先看一下这篇：[【C++ STL】迭代器失效的几种情况总结 - fengMisaka - 博客园](https://www.cnblogs.com/linuxAndMcu/p/14621819.html)
  - 对于关联容器(如 map, set,multimap,multiset)，删除当前的 iterator，仅仅会使当前的 iterator 失效，只要在 erase 时，递增当前 iterator 即可。这是因为 map 之类的容器，使用了红黑树来实现，插入、删除一个结点不会对其他结点造成影响。erase 迭代器只是被删元素的迭代器失效，可以采用`erase(iter++)`的方式删除迭代器。**虽然删除了一个元素，整棵树也会调整以符合红黑树的规范，但是单个节点在内存中的地址没有变化，变化的是各节点之间的指向关系。**

注：实际测试，现在也可以写`it = myMap.erase(it)`，`erase`函数在Modern C++中的返回值是Iterator，所以现在实际上顺序容器（包括链表这种）、关联容器的`erase`都可以统一写成`it = myMap.erase(it)`了。

这里给出一个C++的示例程序，删除map中所有key为偶数的键值对：

```c++
#include <iostream>
#include <map>
#include <cstdlib> // for std::rand and std::srand
#include <ctime>   // for std::time

int main() {
    // 设置随机种子
    std::srand(static_cast<unsigned int>(std::time(nullptr)));

    // 创建一个 map
    std::map<int, int> myMap;

    // 随机插入 20 个键值对
    for (int i = 0; i < 20; ++i) {
        int key = std::rand() % 100; // 生成 0 到 99 的随机数
        int value = std::rand() % 100;
        myMap[key] = value; // 插入到 map 中
    }

    // 删除所有键为偶数的键值对
    for (auto it = myMap.begin(); it != myMap.end();) {
        if (it->first % 2 == 0) { // 检查键是否为偶数
            it = myMap.erase(it); // 删除并更新迭代器
            //这里写myMap.erase(it++)也可以
        }
        else {
            ++it; // 继续下一个元素
        }
    }
    return 0;
}
```



## 【8】解释一下inline函数，inline函数可以是虚函数吗？

> （1）`inline`函数简介：用于**建议**编译器将函数体直接展开到调用处，减少函数调用开销，适用于短小频繁调用的函数。编译器可以忽略此建议；
>
> （2）虚函数可以声明为`inline`，但内联优化仅在编译器可确定具体调用对象时生效（如静态绑定）。通过基类指针/引用的动态调用仍然需要通过虚表查找，内联很可能是无效的。



## 【9】析构函数可以是虚函数么？

> 析构函数最好设置为虚函数：
>
> - 如果析构函数不是虚函数，那么父类指针/引用指向子类对象的时候，析构只会调用父类的析构函数，此时可能会造成子类没有析构完全，造成内存泄漏的问题；
> - 如果析构函数是虚函数，那么父类指针/引用指向子类对象的时候，由于多态的性质，会调用子类的析构函数，而子类的析构函数调用之后会自动调用父类的析构函数，此时是能够正确析构的。

补充：构造函数不能是虚函数，因为调用虚函数需要通过虚表指针查虚表，而调用构造函数时还没有虚表指针。



## 【10】内存泄漏有什么解决方式？

> - （1）智能指针：使用`shared_ptr`，`unique_ptr`等自动管理内存，避免手动delete；尽量使用智能指针或容器（标准库容器会自动管理内存），避免裸指针，减少手动管理内存的机会。
>
> - （2）**RAII**：通过构造函数分配资源，析构函数释放资源，确保资源生命周期与对象绑定；
>
>   - **RAII** 是 "Resource Acquisition Is Initialization"（资源获取即初始化）的缩写。它是**C++ 中一种重要的编程理念和模式**，旨在确保资源的正确管理与释放。
>
>     #### 核心思想：
>
>     1. **资源管理**：RAII 的基本思路是将资源的生命周期绑定到对象的生命周期上。当对象被创建时，它会获取某些资源（如动态内存、文件句柄、网络连接等），而当对象被销毁时，这些资源也会自动释放。这种方式极大地减少了内存泄漏和资源未释放的问题。
>     2. **构造函数与析构函数**：资源的获取通常在构造函数中完成，而资源的释放则在析构函数中完成。这意味着，当一个对象超出作用域时，其析构函数会被自动调用，从而释放相应的资源。



## 【11】智能指针专题：

### （1）了解C++的智能指针么？

> 可以结合游戏引擎的例子，来说明C++的三种常见智能指针。
>
> - （1）`std::unique_ptr`：独占所有权，资源唯一归属，不可复制，可以通过移动转移所有权。
>
>   - **应用场景：**比如管理GO的生命周期，例如单个Enemy对象，确保释放时触发析构逻辑；另一种场景是资源的独占加载，如关卡配置数据（LevelConfig），仅由当前关卡管理器持有（似乎Piccolo有类似的逻辑，==有时间可以验证==）
>
> - （2）`std::shared_ptr`：共享所有权。通过引用计数共享资源，计数归0时自动释放。
>
>   - **应用场景：**例如多个Character实例共享同一纹理（Texture），避免重复加载；或者是在组件系统中，`AIComponent`和`PhysicsComponent`共享统一GO的上下文数据。
>
>   - 实例：
>     ```c++
>     class GameObject
>     {
>     private:
>         std::shared_ptr<Transform> m_transform; //此时Transform即为共享资源
>     };
>     ```
>
> - （3）`std::weak_ptr`：打破循环引用。特点是观察`shared_ptr`资源但不增加引用计数。应用场景为**解决循环依赖。**比如`Player`持有`Weapon`的`shared_ptr`，`Weapon`可以通过`weak_ptr`反向引用`Player`，避免内存泄漏。
>
> 以游戏引擎实践为例，类似资源管理器可以使用`shared_ptr`统一管理资源（如材质，模型），确保跨场景时按需加载/卸载；（在ECS架构中`unique_ptr`可以用于管理独立组件（如RenderSystem），`shared_ptr`用于跨系统共享数据。）
>
> 注：高频创建/销毁的对象（如Particle）可以避免使用智能指针，改用对象池手动管理，从而减少引用计数带来的开销。

C++ 智能指针的使用注意事项（涉及到智能指针的使用语法）：

```c++
#include <memory>
#include <thread>
#include <iostream>
using namespace std;

class Genshin
{
public:
    float version;
    Genshin(float version): version(version){}
};

void Observe(std::weak_ptr<Genshin> wptr) { //weak_ptr的用法
    if (auto sptr = wptr.lock()) {
        std::cout << "value: " << sptr->version << std::endl;
    }
    else {
        std::cout << "wptr lock fail" << std::endl;
    }
}

int main() {
    Genshin g(5.5);
    Genshin g2(5.6);
    std::shared_ptr<Genshin> s1 = std::make_shared<Genshin>(g);
    //std::shared_ptr<Genshin> s2 = std::make_shared<Genshin>(g);
    std::shared_ptr<Genshin> s2 = s1; //这么写才会指向一个control block，使用上一行的话s2.use_count()=1，可能不满足需求
    
    weak_ptr<Genshin> w = s2;
    s1 = std::make_shared<Genshin>(g2);
    s2 = s1;
    std::cout << s2.use_count() << std::endl;
    cout << s2->version << endl;
    Observe(w);
}
//输出结果
/*
2
5.6
wptr lock fail
*/
```



### （2）`unique_ptr`可以作为返回值么？

> 在 C++ 中，`std::unique_ptr` 可以作为函数的返回值。这是一种常见的做法，用于实现独占所有权的资源管理。由于 `unique_ptr` 的特性是不能被复制，但可以被移动，因此当我们将 `unique_ptr` 作为返回值时，**实际发生的是移动语义**，这使得资源能够安全地转移到调用者。以下是一个使用案例：
>
> ```c++
> #include <iostream>
> #include <memory>
> class Resource
> {
> public:
>     Resource() { std::cout << "Resource acquired\n"; }
>     ~Resource() { std::cout << "Resource released\n"; }
> };
> 
> std::unique_ptr<Resource> create_resource()
> {
>     return std::make_unique<Resource>(); //make_unique由C++ 14提供
> }
> 
> int main()
> {
>     std::unique_ptr<Resource> res = create_resource(); //相当于资源被转移到主函数中
>     //do sth with res
>     return 0;
> }
> ```
>
> 移动语义通过 `std::unique_ptr` 的构造和赋值过程得以体现。当 `create_resource` 函数返回时，局部的 `unique_ptr` 被移动到 `main` 函数中的 `res` 变量中，这样有效地转移了对 `Resource` 对象的所有权，而不需要进行任何额外的复制操作



### （3）详细说一下`shared_ptr`是怎么实现的引用计数?

> 在C++中，`shared_ptr`的引用计数机制通过以下步骤实现：
>
> - （1）控制块（Control Block）：每个由`shared_ptr`管理的对象都关联一个控制块，其中包含：
>   - 引用计数：跟踪当前有多少个`shared_ptr`共享该对象
>   - 弱引用计数：跟踪`weak_ptr`的引用数（不影响对象生命周期）
>   - 原始指针
>   - 删除器deleter，自定义释放对象的函数（默认为delete）
> - （2）引用计数的操作
>   - **构造时**：当`shared_ptr`被创建（如通过`make_sharerd`或拷贝构造）时，引用计数**原子地递增**；
>     - 推荐`make_shared`，如果从原始指针构造`shared_ptr`（比如`shared_ptr<T>(new T)`），控制块与对象内存分离，此时同一原始指针初始化多个`shared_ptr`时会导致产生多个控制块，引发双重释放问题。
>   - **析构时**：当`shared_ptr`被销毁或重置时，引用计数**原子地递减**
>     - 若引用计数归零，则调用deleter释放对象内存；
>     - 若弱引用计数也为0，释放控制块内存；
> - （3）**原子性与线程安全**
>   - **原子操作**：引用计数的增减通过原子操作，如`std::atomic<int>`实现，确保多线程环境下的线程安全；
>   - **数据安全**：`shared_ptr`的引用计数是**线程安全的**，但管理的对象本身需要额外同步机制（如互斥锁）来保证线程安全。
>
> 以下是一份玩具智能指针的代码实现（包含基本的`weak_ptr`功能），仅用于展示最基础的功能（不包含原子操作、线程安全与自定义deletor）：
>
> ```c++
> #include <iostream>
> #include <memory>
> using namespace std;
> 
> template<typename T>
> class SharedPtr {
> public:
>     int* counter;
>     int* weakref;
>     T* resource;
> 
>     SharedPtr(T* resc = nullptr) {
>         cout << __PRETTY_FUNCTION__ << endl;
>         counter = new int(1);
>         weakref = new int(0);
>         resource = resc;
>     }
> 
>     SharedPtr(const SharedPtr& rhs) {
>         cout << __PRETTY_FUNCTION__ << endl;
>         resource = rhs.resource;
>         counter = rhs.counter;
>         ++*counter;
>     }
> 
>     SharedPtr& operator=(const SharedPtr& rhs) {
>         cout << __PRETTY_FUNCTION__ << endl;
>         --*counter;
>         if (*counter == 0) {
>             delete counter;
>             delete resource;
>         }
> 
>         resource = rhs.resource;
>         counter = rhs.counter;
>         ++*counter;
>     }
> 
>     ~SharedPtr() {
>         cout << __PRETTY_FUNCTION__ << endl;
>         --*counter;
>         if (*counter == 0) {
>             delete counter;
>             delete resource;
>         }
>     }
> 
>     int use_count() {
>         return *counter;
>     }
> };
> 
> template<typename T>
> class WeakPtr {
> public:
>     T* resource;
> 
>     WeakPtr(T* resc = nullptr) {
>         cout << __PRETTY_FUNCTION__ << endl;
>         resource = resc;
>     }
> 
>     WeakPtr& operator=(SharedPtr<T>& ptr) {
>         cout << __PRETTY_FUNCTION__ << endl;
>         resource = ptr.resource;
>         ++*ptr.weakref;  // 赋值时引用计数counter不变，改变弱引用计数weakref
>     }
> 
>     ~WeakPtr() {
>         cout << __PRETTY_FUNCTION__ << endl;
>     }
> };
> 
> class Son;
> 
> class Father {
> public:
>     SharedPtr<Son> son_;
>     Father() {
>         cout << __PRETTY_FUNCTION__ << endl;
>     }
>     ~Father() {
>         cout << __PRETTY_FUNCTION__ << endl;
>     }
> };
> 
> class Son {
> public:
>     WeakPtr<Father> father_;  // 将SharedPtr改为WeakPtr
>     Son() {
>         cout << __PRETTY_FUNCTION__ << endl;
>     }
>     ~Son() {
>         cout << __PRETTY_FUNCTION__ << endl;
>     }
> };
> 
> int main()
> {
>     auto son_ = new Son();  // 创建一个Son对象，返回指向Son对象的指针son_
>     auto father_ = new Father();  // 创建一个Father对象，返回指向Father对象的指针father_
>     SharedPtr<Son> son(son_);  // 调用SharedPtr构造函数：son.counter=1, son.weakref=0
>     SharedPtr<Father> father(father_);  // 调用SharedPtr构造函数：father.counter=1, father.weakref=0
>     son.resource->father_ = father;  // 调用WeakPtr赋值函数：father.counter=1, father.weakref=1
>     father.resource->son_ = son;  // 调用SharedPtr赋值函数：son.counter=2, son.weakref=0
>     cout << "son: " << son.use_count() << endl;
>     cout << "father: " << father.use_count() << endl;
>     return 0;
> }
> ```

以上代码的输出结果：

```c++
WeakPtr<T>::WeakPtr(T*) [with T = Father]
Son::Son()
SharedPtr<T>::SharedPtr(T*) [with T = Son]
Father::Father()
SharedPtr<T>::SharedPtr(T*) [with T = Son]
SharedPtr<T>::SharedPtr(T*) [with T = Father]
WeakPtr<T>& WeakPtr<T>::operator=(SharedPtr<T>&) [with T = Father]
SharedPtr<T>& SharedPtr<T>::operator=(const SharedPtr<T>&) [with T = Son]
son: 2
father: 1
SharedPtr<T>::~SharedPtr() [with T = Father]
Father::~Father()
SharedPtr<T>::~SharedPtr() [with T = Son]
SharedPtr<T>::~SharedPtr() [with T = Son]
Son::~Son()
WeakPtr<T>::~WeakPtr() [with T = Father]
```



### （4）智能指针是线程安全的么？为什么？

> - `shared_ptr`：
>   - **引用计数原子安全**：增减操作通过C++的原子操作实现，是线程安全的。
>   - **对象访问不安全**：注意，多线程直接读写同一对象需要额外做同步（如互斥锁）
> - `unique_ptr`：
>   - **非线程安全**：独占所有权，转移或者释放需要保证单线程操作；
> - `weak_ptr`：
>   - **依赖`shared_ptr`**，与`shared_ptr`类似，仅引用计数是原子安全的。
>
> 这里我们举个例子，以游戏引擎为例，线程A可以通过`shared_ptr`加载纹理，而线程B可以通过另一`shared_ptr`来访问同一纹理。此时引用计数的增减是安全的，但直接修改纹理像素的话需要加锁。



### （5）智能指针的线程共享机制

> 题目（4）是一个大体上的概括，这里以一个具体的例子来体会多线程中的智能指针应用。
>
> 首先是`unique_ptr`：不能被多个线程共享：`std::unique_ptr `是一种独占所有权的智能指针，意味着同一时间内只有一个 `unique_ptr `可以拥有某个资源。你可以将` unique_ptr `移动到另一个对象（例如通过` std::move`），但不能复制。因此，不同线程之间不能直接共享一个 `unique_ptr`:
>
> ```c++
> void threadFunction(std::unique_ptr<int> ptr) {
>     // 处理 ptr
>     std::cout << "Value: " << *ptr << std::endl;
> }
> 
> int main() {
>     std::unique_ptr<int> ptr = std::make_unique<int>(42);
>     //std::thread t1(threadFunction, ptr); // 编译错误，因为 unique_ptr 不能被复制
>     std::thread t2(threadFunction, std::move(ptr)); // 可以移动
>     t2.join();
> }
> ```
>
> 
>
> 但对于`shared_ptr`来说，是可以的。`std::shared_ptr `可以被多个线程共享：`std::shared_ptr `允许多个指针对象共享同一个资源。它使用引用计数来管理资源的所有权，当最后一个` shared_ptr` 被销毁或重置时，资源才会被释放。因此，可以安全地在多个线程中使用 `shared_ptr` 来共享同一个对象。**引用计数的增加/减少是线程安全的**。**但请务必注意，对智能指针所指向的数据进行修改，并不是线程安全的，可能需要自己维护锁。**
>
> ```c++
> #include <memory>
> #include <thread>
> #include <iostream>
> 
> void threadFunction(std::shared_ptr<int> ptr) {
>     std::cout << "Value: " << *ptr << std::endl;
> }
> 
> int main() {
>     std::shared_ptr<int> ptr = std::make_shared<int>(42);
> 
>     std::thread t1(threadFunction, ptr);
>     std::thread t2(threadFunction, ptr);
> 
>     t1.join();
>     t2.join(); // 两个线程都可以访问同一 shared_ptr
> }
> ```



### （6）介绍一下智能指针的循环引用问题

> 循环引用指两个或多个对象通过`std::shared_ptr`相互持有对方的所有权，导致引用计数无法归零，内存无法释放，引发内存泄漏的问题。
>
> **解决方案：使用`std::weak_ptr`替代单向的`shared_ptr。`**存在双向依赖时，需要将一方的`shared_ptr`替换为`weak_ptr`。

```c++
#include <memory>
#include <thread>
#include <iostream>
using namespace std;

class Honkai;
class Genshin
{
public:
    float version;
    std::shared_ptr<Honkai> game;
    Genshin(float version): version(version){}
    ~Genshin(){ cout << "genshin" << endl; }
};

class Honkai
{
public:
    float version;
    std::weak_ptr<Genshin> game;  //（1）如果这里是shared_ptr，则不会调用析构函数，造成内存泄漏
    Honkai(float version) : version(version) {}
    ~Honkai() { cout << "honkai" << endl; }
};

int main() {
    shared_ptr<Genshin> g = make_shared<Genshin>(1.2);
    shared_ptr<Honkai> h= make_shared<Honkai>(2.2);
    h->game = g;
    g->game = h; //造成循环引用的根源
    
    cout << g->game.use_count() << endl; //都是shared_ptr的情况下，这两个都是2
    cout<< h->game.use_count() << endl;
}
```



## 【12】介绍一下C++的多态

C++ 中的多态是指在不同上下文中以不同方式表现的能力，主要分为两种类型：

- **编译时多态（静态多态）**：在编译器即可确定调用哪个函数，包括运算符重载、函数重载和模板；
- **运行时多态（动态多态）**：使用虚函数来实现。接下来回答就可以往虚函数上引了。



## 【13】关于函数重载，为什么不能仅靠返回值不同判断

**函数重载**是指在同一个作用域内，允许存在多个同名但参数列表不同的函数。编译器通过函数的参数数量或类型来决定调用哪个重载函数。

**特点：**

- **参数不同**：可以根据参数的数量、类型或顺序来区分。
- **返回值无关**：重载函数的返回值类型可以相同或不同，但不能仅依靠返回值来区分。

之所以不能够仅靠返回值来做不同判断，是因为如果两个重载函数的参数完全相同，只是返回值不同，编译器无法通过返回值来确定调用哪一个函数，**因为函数调用的上下文是在选择参数时就已经确定了，而并非在函数返回后。**换句话说，**函数返回值的类型是调用函数后的结果，与函数调用本身的决策过程无关。**

> 补充：关于重载和const形参：
>
> - 顶层`const`不影响传入函数的对象。一个拥有顶层`const`的形参无法和另一个没有顶层`const`的形参区分开来。
>   - 回忆：**顶层const可以表示任意的对象是常量（包括指针、类、基本数据类型等）**，底层const则与指针或引用的基本类型部分有关。指针既可以是顶层const也可以是底层const。const引用都是底层const。
> - 比如：
>
> ```c++
> void print(Genshin g){} //(1)
> void print(const Genshin g){} //(2)
> //(1)和(2)不构成重载
> void print(Genshin* g){} //(3)
> void print(Genshin* const g){} //(4):属于顶层const
> //(3)和(4)也不构成重载
> ```
>
> 另一方面，如果形参是某种类型的指针或引用，则通过区分其指向的是常量对象还是非常量对象可以实现函数重载，此时的`const`是底层的，比如以下四个函数均构成重载：
>
> ```c++
> void print(Genshin* g){}
> void print(const Genshin* g){}
> void print(Genshin& g){} //(3)
> void print(const Genshin& g){} //(4)
> const Genshin g;
> print(g); //(4)
> ```
>
> 对于const对象或者指向const的指针来说，只能传递给const形参。理论上，非常量可以转为const，所以非常量既可以调用非常量版本也可以调用常量版本。但**当我们传递一个非常量对象或者指向非常量对象的指针时，编译器会优先选用非常量版本的函数。**

注：以下两个不构成重载，因为编译器不知道调用哪个：

```c++
void print(const Genshin g) { cout << "value" << endl; }
void print(const Genshin& g) { cout << "ref" << endl; }
```



## 【14】C++各种关键字/基础特性

### （1）volatile关键字

可参考：[C/C++ 中 volatile 关键字详解 | 菜鸟教程](https://www.runoob.com/w3cnote/c-volatile-keyword.html)

- `volatile`：`volatile` 关键字是一个类型修饰符，用于指示编译器某个变量可能会在任何时刻被外部因素更改，例如硬件或其他线程。这一修饰符的主要作用是告诉编译器不要对该变量进行优化，从而确保每次访问该变量时都直接读取其最新的值。**这防止了编译器在优化代码时，将多个访问合并成一次。**
  - 注：**不提供线程安全**：虽然 `volatile` 可以确保变量的最新值，但它并不提供原子性和线程安全。如果多个线程同时访问同一个 `volatile` 变量，仍然可能会出现竞争条件，因此通常还需要其他同步机制（如互斥锁）。



### （2）extern C

当 C++ 代码需要调用 C 函数时，可以使用 `extern "C"` 声明这些函数，以防止 C++ 的名称修饰（name mangling），确保链接器能够找到正确的 C 函数。一份使用的案例：

```c++
#ifdef __cplusplus
extern "C" {
#endif

void myCFunction(); // C 函数声明

#ifdef __cplusplus
}
#endif
```

`extern "C"` 使得 C++ 能够与 C 代码进行链接，确保 C 函数在 C++ 环境中的正确调用和链接。使用场景包括： 1.在C++中包含C的头文件 2.混合C和C++的开发。



### （3）`const`含义，有什么作用？

- （1）**const用于定义常量**：const定义的常量编译器可以对其进行数据静态类型安全检查。

- （2）**const修饰函数的形参**：当输入参数为用户自定义类型和抽象数据类型时，可以考虑将”值传递“改为”const &传递“，可以提高效率。

- （3）**const修饰函数的返回值**：比如给”指针传递“的函数返回值加const,则返回值不能被直接修改，且该返回值只能被赋值给加const修饰的同类型指针。

  如：

  ```c++
  const char* Miemie(void){};
  char* ch = Miemie();//报错
  const char* ch = Miemie();//正确
  ```

- （4）**const修饰类的成员函数**：任何不会修改数据成员的函数都应该用const修饰，这样，当不小心修改了数据成员或者调用了非const成员函数，编译器都会报错。

```c++
class Genshin
{
public:
    int c;
    void sub(int b){ }
    void add(int a) const
    {
        //c = 3; ERROR:不能修改类内变量
        a = 10; //a可以改，因为是形参
        //sub(a); ERROR:因为const成员函数只能调用const成员函数
    }
};
```



## 【15】C++模板

C++模板是一种支持泛型编程的工具，允许编写与数据类型无关的代码，在**编译时**生成具体类型的实现。

- 从类型来看，模板分为函数模板（比如max函数）和类模板（例如`vector`）。
- 模板参数：可以是类型参数`typename T`，也可以是非类型参数（例如整型/指针等常量），比如一个数组大小`int N`
- 实例化方式：隐式（编译器自动推导类型），或者显式（比如`func<int>`） 
- 特化机制：
  - **全特化：**针对全部参数定制实现
  - **偏特化：**部分参数定制/条件约束（如指针特化）



### （1）全特化与偏特化

下面给出一个全特化和偏特化的例子：

```c++
#include <iostream>

// 通用模板定义
template <typename T, typename U>
class Pair {
public:
    Pair(T first, U second) : first(first), second(second) {}

    void display() {
        std::cout << "Generic Pair: (" << first << ", " << second << ")" << std::endl;
    }

private:
    T first;
    U second;
};

// 全特化：针对 int 类型的 Pair
template <>
class Pair<int, int> {
public:
    Pair(int first, int second) : first(first), second(second) {}

    void display() {
        std::cout << "Specialized Pair for ints: (" << first << ", " << second << ")" << std::endl;
    }

private:
    int first;
    int second;
};

// 偏特化：当第二个参数为 int 类型时
template <typename T>
class Pair<T, int> {
public:
    Pair(T first, int second) : first(first), second(second) {}

    void display() {
        std::cout << "Partial Specialized Pair with int as second type: ("
            << first << ", " << second << ")" << std::endl;
    }

private:
    T first;
    int second;
};

int main() {
    Pair<double, double> genericPair(2.5, 3.0);
    genericPair.display(); // 调用通用版本

    Pair<int, int> specializedPair(114514, 1919810);
    specializedPair.display(); //调用全特化版本

    Pair<std::string, int> partialSpecializedPair("Hello", 42);
    partialSpecializedPair.display(); // 调用偏特化版本

    return 0;
}
```



### （2）可变参数模板

在 C++11 及更高版本中，可变参数模板（Variadic Templates）是一种强大的功能，允许你定义可以接受任意数量参数的模板。这在处理不确定数量的参数时非常有用，比如实现类似于 `printf` 的功能。可变参数模板在 C++ 中**通过递归展开参数包的机制实现**，是通过使用 `...` 语法来定义和操作参数包的。以下是一个可变参数模板实现任意数量参数的`print`方法：

```c++
#include <iostream>
using namespace std;

void print() //需要定义一个基础版本的 print 函数，当没有更多参数时，它仅输出一条消息。
{
	cout << " nothing" << endl;
}

template<typename T, typename... Args>
void print(T first, Args... args) //它接受至少一个参数 T first 和零个或多个额外参数 Args... args
{
	std::cout << first << " ";
	print(args...);  // 递归调用，处理剩余参数
}

int main()
{
	print("1", 2, 1.14514, 'a', true); //1 2 1.14514 a 1  nothing
}
```

实际应用：**日志记录系统**：可变参数模板可以方便地创建一个日志记录函数，支持多种数据类型的参数。以及STL中`vector`实现的`emplace_back`方法就实现了可变参数模板+完美转发。



### （3）模板萃取

> 可以参考的进阶阅读材料：[C++-模板-萃取的实现(一) - 知乎](https://zhuanlan.zhihu.com/p/559936879)，以及后续文章。目前只看了（一）和（二）的一部分，暂时对模板萃取有一个大致的认知即可。另两个进阶阅读材料：[C++模板进阶指南：SFINAE - 知乎](https://zhuanlan.zhihu.com/p/21314708)，[C++：STL中的萃取器traits - 知乎](https://zhuanlan.zhihu.com/p/547313994)。==这几个进阶阅读材料还没有看完，比较难，有遇到这么难的题目再说吧。==

C++中的模板萃取是一种通过模板技术提取类型特性（如类型属性、行为等）的编程模式，**常用于在编译期根据类型的不同特性选择不同的实现逻辑**，其核心是通过**模板特化或偏特化**定义类型的元信息，供其他模板代码使用。

**模板萃取的核心思想**

- 1.定义Traits类：通过模板类封装类型的元信息（如是否是指针、是否有特定成员等）
- 2.特化Traits：针对不同类型，通过特化为其赋予不同的元信息
- 3.编译器逻辑分发：基于Traits的元信息，在编译器选择不同的代码分支。



示例1：判断类型是否为指针（实现的是**类型特征（Type Traits）**）。

- **编译时决策**：编译器能够在编译阶段确定 `is_pointer<int>::value` 和 `is_pointer<int*>::value` 的值，从而使得这个代码在类型检查和性能上都很高效。

```c++
#include <iostream>

//基础模板:默认不是指针
template<typename T>
struct is_pointer {
	static const bool value = false;
};
//特化版本:当类型是指针时匹配
template<typename T>
struct is_pointer<T*> {
	static const bool value = true;
};

int main()
{
	std::cout << std::boolalpha; //输出流将bool值解析为true/false,否则输出1/0
	std::cout << is_pointer<int>::value << std::endl; //false
	std::cout << is_pointer<int*>::value << std::endl; //true
	return 0;
}
```



**示例2：根据类型选择不同实现。**假设需要为整数类型和浮点数类型提供不同的处理逻辑：

```c++
#include<iostream>
#include<type_traits>

//1.Traits类定义类型分类
template<typename T>
struct number_category {
	static const char* value;
};

//2.模板特化
template<> const char* number_category<int>::value = "Integer";
template<> const char* number_category<double>::value = "Double";

//3.根据Traits分发逻辑
template<typename T>
void process(T val){
	std::cout << "Processing number: " << val << "(" << number_category<T>::value << ")" << std::endl;
}

int main(){
	process(114514); //Processing number: 114514(Integer)
	process(3.14); 	//Processing number : 3.14(Double)
}
```



**示例3：STL中的迭代器萃取(iterator_traits)**

STL通过`iterator_traits`提取迭代器的类型信息（如value_type）：

```c++
#include<iostream>
#include<type_traits>
#include<vector>
#include<iterator>

template<typename Iterator>
void print_value_type(Iterator it)
{
	//通过STL的iterator_traits萃取迭代器的value_type
	using value_type = typename std::iterator_traits<Iterator>::value_type;
	std::cout << "Value type: " << typeid(value_type).name() << std::endl; //typeid的介绍：https://blog.csdn.net/HandsomeHong/article/details/115038507
}

int main()
{
	std::vector<int> vec={ 1,2,3 };
	print_value_type(vec.begin()); //Value type: int
	return 0;
}
```



**模板萃取的典型应用场景：**

1. **类型检查**：如 `std::is_pointer<T>`, `std::is_integral<T>`。
2. **算法优化**：根据迭代器类型（随机访问/双向）选择最优实现（如 `std::advance`）。
3. **策略分发**：通过 `std::enable_if`（过于黑魔法了） 或 `if constexpr` 实现编译期条件分支。
4. **容器适配**：萃取类型的特定成员（如 `value_type`、`iterator`）。



## 【16】C++动态内存分配有什么方式

> 这道题目应该就是考察new/delete，以及可以顺便答一下malloc/free
>
> | 特性             | `new` / `delete`                               | `malloc` / `free`              |
> | ---------------- | ---------------------------------------------- | ------------------------------ |
> | **内存分配方式** | 使用构造函数（调用对象的构造函数）             | 只分配原始内存，不调用构造函数 |
> | **内存释放方式** | 使用析构函数（调用对象的析构函数）             | 不调用析构函数                 |
> | **返回值类型**   | 返回特定类型的指针                             | 返回 `void*` 类型的指针        |
> | **异常处理**     | 如果内存分配失败，会抛出 `std::bad_alloc` 异常 | 如果分配失败，会返回 `nullptr` |
> | **用法**         | 用于对象的创建和销毁                           | 用于原始内存的分配和释放       |
> | **初始化**       | 支持初始化                                     | 不支持初始化                   |
> | **重载**         | 可以重载 `new` 和 `delete`                     | 不可重载                       |
> | **类型安全**     | 类型安全，编译时检查                           | 类型不安全，需手动转换类型     |
>
> ### 总结
>
> - **`new` 和 `delete`**：推荐用于对象的动态分配和释放，能够保证对象的构造和析构，并且支持类型安全。
> - **`malloc` 和 `free`**：通常用于 C 风格的内存管理，只适合简单的内存分配，不适用于对象的管理。
>
> 在 C++ 中，建议优先使用 `new` 和 `delete` 来进行动态内存管理，以保持类型安全和资源管理的一致性。

注：new/delete和malloc/free不要混搭，可能会导致内存管理出现问题。



## 【17】C++中`new`和`delete`都是怎么实现的？

可参考这篇：[C++：带你理解new和delete的实现原理new和delete是用户进行动态内存申请和释放的操作符，operator - 掘金](https://juejin.cn/post/7023663734367191076)，基本涵盖了这部分的面试题目。默认的实现是：

- `new`：调用`operator new`分配内存，再调用构造函数初始化对象；
- `delete`：调用析构函数销毁对象，再调用`operator delete`释放内存；

**new和delete**是用户进行**动态内存申请和释放的操作符**，**operator new 和operator delete**是系统提供的**全局函数**，**new在底层调用operator new**全局函数来申请空间，**delete在底层通过operator delete**全局函数来释放空间。`operator new`和`operator delete`本身可能是由malloc和free来实现的。

注：栈上对象使用默认的内存管理，不会调用 `operator new` / `operator delete`。

- **衍生问题1：构建一个只能在栈上创建的类；**
- **衍生问题2：构建一个只能在堆上创建的类；**

这两个问题上面链接里有答案。

- **衍生问题3：placement new**
  - [placement new机制 - 知乎](https://zhuanlan.zhihu.com/p/228001107)
- **衍生问题4：重载new operator和delete operator**
  - 注意，`new operator`和`operator new`是两个概念，后者指的是C++的全局函数，是不能够重载的，而`new operator`是类可以自己重载的操作符。举个例子：

```c++
#include<iostream>
#include<type_traits>
#include<vector>
#include<iterator>
using namespace std;

class MyClass {
public:
    static void* operator new(size_t size) {
        std::cout << "Custom new: Allocating " << size << " bytes.\n";
        void* p = std::malloc(size);
        if (!p) {
            throw std::bad_alloc();
        }
        return p;
    }

    static void operator delete(void* p) noexcept {
        std::cout << "Custom delete: Releasing memory.\n";
        std::free(p);
    }

    // 构造函数和析构函数
    MyClass() { std::cout << "MyClass constructor called.\n"; }
    ~MyClass() { std::cout << "MyClass destructor called.\n"; }
};

int main()
{
    // 动态分配
    MyClass* obj1 = new MyClass();
    delete obj1;

    // 栈上分配
    MyClass obj2; // 这里不会调用 operator new/delete
	return 0;
}
```

这段代码的输出结果为：

> Custom new: Allocating 1 bytes.
> MyClass constructor called.
> MyClass destructor called.
> Custom delete: Releasing memory.
> MyClass constructor called.
> MyClass destructor called.



## 【18】函数调用的过程具体是怎么样的？比如入栈顺序

> 函数调用时的栈操作顺序如下：
>
> - 1.caller的参数压栈：按照从右到左的顺序依次压入参数（比如`func(a,b,c)`,此时先压c，再压b，再压a）；
> - 2.返回地址：执行`call`指令，将下一条指令地址（返回地址）压入栈；
> - 3.保存旧ebp：被调用函数通过push ebp保存调用者的基址指针（注：`push` 指令用于将一个寄存器或值压入栈中）；
> - 4.设置新的ebp：`mov ebp, esp`，将esp的值赋值给ebp，此时就可以通过ebp对栈进行操作；
> - 5.分配局部变量：比如`sub esp N`，调整栈顶，预留空间给局部变量和临时数据；
> - 6.执行函数体：访问参数通过ebp+偏移量（比如64位机器下，第一个函数内参数在ebp+8）；
> - 7.恢复栈帧：`mov esp ebp`，此时把ebp的值赋给esp，于是esp就指到了ebp，释放局部变量空间。接着`pop ebp`：pop的语义很重要，**pop ebp的意思是把当前栈顶的元素出栈，送入ebp中**，而不是让ebp出栈。
> - 8.返回调用者：`ret`弹出返回地址，跳转回调用处；
>
> 以上过程最好能够清晰的理解。

重要知识点：

![img](%E9%9D%A2%E7%BB%8F%E5%90%88%E9%9B%86%E2%80%94%E2%80%94%E9%A2%98%E7%9B%AE+%E7%AD%94%E6%A1%88%E7%89%88.assets/1134295-ce2aa08820b11888.webp)

可以参考：[对于ESP、EBP寄存器的理解 - 狂奔~ - 博客园](https://www.cnblogs.com/xiangtingshen/p/11221277.html)

- **esp是栈指针**，是cpu机制决定的，push、pop指令会自动调整esp的值；
- **ebp只是存取某时刻的esp**，**这个时刻就是进入一个函数内后，cpu会将esp的值赋给ebp，此时就可以通过ebp对栈进行操作，比如获取函数参数，局部变量等，实际上使用esp也可以；**
  - 既然使用esp也可以，那么为什么要设定ebp呢？
  - 答案是为了方便程序员。**因为esp在函数运行时会不断的变化，所以保存一个一进入某个函数的esp到ebp中会方便程序员访问参数和局部变量，而且还方便调试器分析函数调用过程中的堆栈情况**。前面说了，这个ebp不是必须要有的，你非要使用esp来访问函数参数和局部变量也是可行的，只不过这样会麻烦一些。
- 调用一个函数时，**先将堆栈原先的基址（EBP）入栈，以用来保存之前任务的信息。然后将栈顶指针的值赋给EBP，将之前的栈顶作为新的基址（栈底），然后再这个基址上开辟相应的空间用作被调用函数的堆栈。**函数返回后，从EBP中可取出之前的ESP值，使栈顶恢复函数调用前的位置；再从恢复后的栈顶可弹出之前的EBP值，因为这个值在函数调用前一步被压入堆栈。这样，EBP和ESP就都恢复了调用前的位置，堆栈恢复函数调用前的状态。原文链接：https://blog.csdn.net/qq_25814297/article/details/113475019

推荐先看这篇：[C函数调用过程原理及函数栈帧分析 - stardsd - 博客园](https://www.cnblogs.com/sddai/p/9762968.html)。直接来看下面这个例子对应的汇编，自己分析一下（==分析的不一定对，先放这里，应该也差不多，忘了可以看看。==）：

```c++
int add(int a, int b)
{
	int c = a;
	int d = b;
	return c + d;
}

int main()
{
	add(114514, 1919810);
	return 0;
}
```

对应的汇编如下：

![image-20250206172440290](%E9%9D%A2%E7%BB%8F%E5%90%88%E9%9B%86%E2%80%94%E2%80%94%E9%A2%98%E7%9B%AE+%E7%AD%94%E6%A1%88%E7%89%88.assets/image-20250206172440290.png)

```c++
add(int, int):
        push    rbp  //将当前基指针 (rbp) 压入栈中，以保存调用此函数之前的基指针值，为新的栈帧准备空间。
        mov     rbp, rsp //更新基指针 (rbp) 为当前栈顶指针 (rsp)，这标志着新栈帧的开始。这样后续的局部变量和参数都可以通过 rbp 进行访问。
        mov     DWORD PTR [rbp-20], edi //将第一个参数（传递给 add 的整数 a，存储在寄存器 edi 中）存储到栈帧中的位置 [rbp-20]。这个位置用于保存局部变量或参数。
        mov     DWORD PTR [rbp-24], esi //将第二个参数（传递给 add 的整数 b，存储在寄存器 esi 中）存储到栈帧中的位置 [rbp-24]。
        mov     eax, DWORD PTR [rbp-20] //从栈帧中读取 [rbp-20] 处的值（参数 a），并将其移动到 eax 寄存器中。eax 是返回值的寄存器。
        mov     DWORD PTR [rbp-4], eax //将 eax 中的值（即 a 的值）存储到 [rbp-4], 用于后续计算。
        mov     eax, DWORD PTR [rbp-24] //从栈帧中读取 [rbp-24] 处的值（参数 b），并将其移动到 eax 寄存器中。
        mov     DWORD PTR [rbp-8], eax //将 eax 中的值（即 b 的值）存储到 [rbp-8]，为后续计算做准备。
        mov     edx, DWORD PTR [rbp-4] //将 [rbp-4]（即 c 的值）加载到 edx 寄存器中，准备进行加法运算。
        mov     eax, DWORD PTR [rbp-8] //将 [rbp-8]（即 d 的值）加载到 eax 寄存器中，准备进行加法运算。
        add     eax, edx //将 edx 中的值（c）与 eax 中的值（d）相加，结果存储在 eax 中。此时 eax 中有 c + d 的值，即函数的返回值。
        pop     rbp //从栈中弹出之前保存的基指针值，恢复调用该函数之前的栈帧。
        ret //返回到调用该函数的位置，返回值存储在 eax 中。
main:
        push    rbp // 将当前基指针 (rbp) 压入栈中，以保存调用此函数之前的基指针值。
        mov     rbp, rsp //更新基指针 (rbp) 为当前堆栈顶指针 (rsp)，为新的栈帧准备空间。MOV用法：MOV DST SRC
        mov     esi, 1919810 //将整数 1919810 存储到寄存器 esi，这是add 函数的第二个参数。
        mov     edi, 114514 //将整数 114514 存储到寄存器 edi，这是 add 函数的第一个参数。
        call    add(int, int) //调用add函数
        mov     eax, 0
        pop     rbp
        ret
```

其中rbp和rsp和上文链接中的ebp和esp是类似的，只不过ebp是x86架构，而rbp是x86-64架构。`rsp`（栈指针寄存器）在 x86 和 x86_64 架构中是自动管理的，它始终指向当前栈顶的位置。每当进行入栈（push）或出栈（pop）操作时，这个寄存器的值会相应地更新。`rbp` 是一个寄存器，用于指向当前函数的栈帧的起始位置。

**栈帧的大小是由编译器在编译时自动确定的。编译器根据函数的局部变量、参数、返回地址以及其他需要存储的信息来计算栈帧的大小。这些信息影响了栈帧的布局和大小。**

在函数调用时，通常会将上一个函数的 `rbp` 值压入栈中，然后将其更新为当前的 `rsp`（栈顶指针）。

通常情况下，负偏移（如 `rbp-20`）用于访问局部变量，而正偏移（如 `rbp+20`）则用于访问函数参数。

- 每次执行 `push` 指令时，`rsp` 会先减去 8（在 64 位架构下，每次入栈 8 字节），然后将要压入的值写入新 `rsp` 指向的地址。
- 每次执行 `pop` 指令时，`rsp` 会先读取当前 `rsp` 指向的值，然后再加上 8（在 64 位架构下），以调整栈指针。



## 【19】STL各种容器分析

这个在`C++面经合集.md`里面都有总结，内容比较多，就不再粘过来了。其他那篇里没总结的内容放在这里。



## 【20】C++中有什么锁？

可以参考的链接：[C++锁（万字长文）：概念、不同锁实现、死锁现象+代码实例+预防+避免、加锁性能降低8种有效策略-腾讯云开发者社区-腾讯云](https://cloud.tencent.com/developer/article/2481793)

| **锁类型**                      | **特点**                               | **优点**                       | **缺点**                              | **适用场景**                 |
| :------------------------------ | :------------------------------------- | :----------------------------- | :------------------------------------ | :--------------------------- |
| 互斥锁 (`std::mutex`)           | 简单的二进制锁，线程间互斥访问共享资源 | 实现简单、适用广泛             | 阻塞线程，可能导致上下文切换开销      | 共享资源需要严格互斥的场景   |
| 递归锁 (`std::recursive_mutex`) | 同一线程可以多次加锁，无需担心死锁     | 避免递归调用时死锁问题         | 性能略差于普通互斥锁                  | 递归函数需要加锁的场景       |
| 读写锁 (`std::shared_mutex`)    | 多线程可并发读取，但写操作独占         | 提高读操作多的场景下的并发性能 | 写操作需要独占锁，读多写少时性能最佳  | 数据读多写少的场景           |
| 自旋锁 (`std::atomic_flag`)     | 线程忙等待，不阻塞，适合短期锁         | 低延迟，无需上下文切换         | 忙等待消耗CPU资源，不适合长时间锁持有 | 短期锁定操作或实时性高的场景 |

==这个问题水很深，而且掌握的不好。暂时就只整理概念相关的内容，等其他面经刷到了更深入的问题再来整理吧。==



## 【21】简单题目合集

### （1）数组和链表的区别是什么？新增一个元素，数组和链表的区别？

### （2）指针和引用区别



# 操作系统篇

## 【1】操作系统进程和线程的区别？

> 参考链接：[操作系统之进程和线程（二者的区别，进程的状态切换、创建、终止、上下文切换）_进程上下文切换和线程上下文切换-CSDN博客](https://blog.csdn.net/u014454538/article/details/99330919)。
>
> - **进程（Process）是资源分配的基本单位，线程（Thread）是CPU调度的基本单位。**线程不拥有资源，但可以共享进程资源（如内存空间和文件描述符表）。同一进程中的线程切换，不会引起进程切换；不同进程中的线程切换，会引起进程切换。
> - 线程将进程的资源分和CPU调度分离开来。 以前进程既是资源分配又是CPU调度的基本单位，后来为了更好的利用高性能的CPU，将资源分配和CPU调度分开。因此，出现了线程。
> - 进程和线程的联系： 一个线程只能属于一个进程，一个进程可以拥有多个线程。线程之间共享进程资源。
>
> 比如：**进程和线程的实例：** 打开一个QQ，向朋友A发文字消息是一个线程，向朋友B发语音是一个线程，查看QQ空间是一个线程。QQ软件的运行是一个进程，软件中支持不同的操作，需要由线程去完成这些不同的任务。



## 【2】线程的通信方式有哪些？

> 可以参考的链接：[C++ 并发编程指南（10）线程间通信_c++ 线程间通信-CSDN博客](https://blog.csdn.net/cloud323/article/details/136620168)
>
> **线程通信就是当多个线程共同操作共享的资源时，互相告知自己的状态以避免资源争夺。**线程通信主要可以分为两种方式，分别为**共享内存**、**消息传递**。另外还有管道流的方式，使用较少，就不整理了。每种方式有不同的方法来实现：
>
> - （1）**共享内存**：共享内存是一种常见的线程间通信方式，多个线程可以访问和修改同一块内存区域中的数据。在C++中，全局变量、静态变量和堆上分配的对象都可以作为共享内存。为了避免数据竞争，需要使用同步原语，如互斥锁来保护共享数据的访问。例如，使用`std::lock_guard`和`std::mutex`来保护共享变量的访问。也可以使用**信号量**，信号量是一种同步原语，用于线程间的通信。它允许多个线程共享一个计数器，从而控制对资源的访问。
>   - 以及C++中提供了`volatile`关键词，用它声明的类型变量表示可以被某些编译器未知的因素更改，比如：操作系统、硬件或者其它线程等。**遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问。**当要求使用 volatile 声明的变量的值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。而且读取的数据立刻被保存。
> - （2）**消息传递：**消息传递和管道是另一种线程间通信方式，它们允许线程通过发送和接收消息来交换信息。虽然C++标准库没有直接提供消息传递和管道的实现，但可以使用第三方库或自定义数据结构来实现。例如，使用`std::queue`和条件变量来实现一个简单的消息队列。**具体可以参考上面那个链接**。



## 【3】什么是死锁？死锁的必要条件

[C++锁（万字长文）：概念、不同锁实现、死锁现象+代码实例+预防+避免、加锁性能降低8种有效策略-腾讯云开发者社区-腾讯云](https://cloud.tencent.com/developer/article/2481793)

**死锁（Deadlock）**是指两个或多个线程或进程因争夺资源而相互等待，导致所有参与者都无法继续执行的状态。

根据 **Coffman** 在 1971 年提出的理论，死锁的发生需要满足以下四个条件，这些条件同时成立时，系统可能进入死锁状态：

| **条件**                                   | **描述**                                                     |
| :----------------------------------------- | :----------------------------------------------------------- |
| **互斥（Mutual Exclusion）**               | 至少有一个资源是非共享的，某一时刻只能被一个线程或进程占用。 |
| **请求与保持/占有且等待（Hold and Wait）** | 线程已经持有资源，同时又请求新的资源，但未释放已有资源。     |
| **不可剥夺（No Preemption）**              | 已被分配的资源不能强制剥夺，只能由持有该资源的线程或进程主动释放。 |
| **循环等待（Circular Wait）**              | 存在一个线程或进程的循环等待链，链中的每个线程或进程都在等待下一个线程持有的资源。 |

下面通过一个C++多线程的例子，深入理解一下死锁：

```c++
#include <iostream>
#include <thread>
#include <mutex>
#include <chrono>

std::mutex mutex1;
std::mutex mutex2;

void threadFunction1() {
    std::cout << "Thread 1: Trying to lock mutex1...\n";
    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // 确保线程顺序

    std::lock_guard<std::mutex> lock1(mutex1);
    std::cout << "Thread 1: Locked mutex1.\n";
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
    std::cout << "Thread 1: Trying to lock mutex2...\n";
    std::lock_guard<std::mutex> lock2(mutex2); // 可能导致死锁
    std::cout << "Thread 1: Locked mutex2.\n";
}

void threadFunction2() {
    std::cout << "Thread 2: Trying to lock mutex2...\n";

    std::lock_guard<std::mutex> lock2(mutex2);
    std::cout << "Thread 2: Locked mutex2.\n";
    std::this_thread::sleep_for(std::chrono::milliseconds(120)); // 等待一段时间
    std::cout << "Thread 2: Trying to lock mutex1...\n";
    
    std::lock_guard<std::mutex> lock1(mutex1); // 可能导致死锁
    std::cout << "Thread 2: Locked mutex1.\n";
}

int main() {
    std::thread t1(threadFunction1);
    std::thread t2(threadFunction2);

    t1.join();
    t2.join();

    std::cout << "Main thread: Finished execution.\n";
    return 0;
}
```

在这个例子中：

- mutex 又称互斥量，C++ 11中与 Mutex 相关的类（包括锁类型）和函数都声明在 <mutex> 头文件中，所以如果你需要使用 std::mutex，就必须包含 <mutex> 头文件。
- `std::lock_guard`，与 Mutex RAII 相关，方便线程对互斥量上锁
- **mutex1 和 mutex2**：两个互斥资源。
- **死锁场景**：线程 1 持有 `mutex1`，等待 `mutex2`；线程 2 持有 `mutex2`，等待 `mutex1`。

上述程序的输出结果为：

```c++
Thread 1: Trying to lock mutex1...
Thread 2: Trying to lock mutex2...
Thread 2: Locked mutex2.
Thread 1: Locked mutex1.
Thread 2: Trying to lock mutex1...
Thread 1: Trying to lock mutex2...
```

主函数没有输出最后一句，说明发生了死锁。



### ==（1）如何预防死锁？==

[C++锁（万字长文）：概念、不同锁实现、死锁现象+代码实例+预防+避免、加锁性能降低8种有效策略-腾讯云开发者社区-腾讯云](https://cloud.tencent.com/developer/article/2481793) 这篇文章里有更为详细的介绍。



# 游戏算法篇

## 【1】介绍下A*算法。`A*`算法的缺点

> （1）A* 算法是一种用于路径寻找和图形遍历的启发式搜索算法。它结合了 Dijkstra 算法的最佳优先策略和贪婪最佳优先搜索，使用一个评价函数 `f(n) = g(n) + h(n)`，其中：
>
> - `g(n)`：从起点到当前节点 n 的实际成本。
> - `h(n)`：当前节点 n 到目标节点的估计成本（启发式）。
>
> **具体算法的细节如果有额外问再做回答。**大致思路是维护一个`openList`和`closeList`，每次从`openList`中取出`F`值最小的格子，放入`closeList`中，并把周围符合要求的（比如非障碍物，非`closeList`中的点）放入到`openList`中，如果周围点的`G`值可以更新（此时会在`openList`里面），则会更新为更小的`G`值（当然，F也会顺便更新）,直到找到终点或者`openList`为空（表示没有可行路径）。
>
> 该算法确保尽量找到最短路径（其实，启发式函数`H`很可能会导致寻路结果不是最短路径）并且高效性相对较好。
>
> （2）A*算法的缺点：
>
> - **计算资源消耗**：在复杂环境中，A* 可能需要大量记忆体和计算力（想象一下，1000*1000的网格），因为它会维护多个开放和关闭列表。
> - **启发式函数依赖**：性能高度依赖于选择合适的启发式函数，不同的选择可能导致效率降低。
> - **不太适用于动态环境和复杂地形**：如果环境不断变化，A* 需要重新计算路径，造成额外开销（比如移动的NPC）。同时，斜坡，高低差等地形不太好处理。
> - 锯齿形路径：很多时候会导致路径的不自然。
>
> （3）`A*`算法本身并未被淘汰，但在纯Grid环境中使用A*会导致上述的几个问题。现在游戏中常用的应该是`Navmesh`的寻路，这在其他题目中会专门介绍。



### （1）A*算法和Dijkstra算法的区别

A* 算法可以被视为在 Dijkstra 算法的基础上引入了启发式元素 ( H ) 的一种改进。通过合理选择 ( H )，A* 能够比 Dijkstra 更快速地找到最短路径。选择合适的启发式函数对于 A* 算法的性能至关重要。这里给出一些准则：

- 如果选择的启发式函数过于乐观（低估实际成本，可以思考极限情况下H=0），A* 算法可能会变得与 Dijkstra 算法一样慢，因为它会探索过多的节点。
- 如果启发式函数过于悲观（高估实际成本），则可能导致 A* 算法无法找到最优路径。想象一下H项远大于G，那么就会退化为贪婪最佳优先搜索算法。



## 【2】快速排序的原理和时间复杂度

> 在排序算法对应的章节中，有对快排进行介绍。
>
> - （1）基本思路：找一个`pivot`，通常选中间或者随机元素（避免最坏情况），然后做`partition`操作，将小于基准的元素移到左侧，将大于基准的移到右侧，基准归为到最终位置，然后对左右子数组递归重复上述过程。
> - （2）快速排序的平均时间复杂度为$O(nlogn)$，最坏的时间复杂度是$O(n^2)$，是不稳定的排序；



# 设计模式篇

## 【1】介绍一下单例模式

> 这里可以引导说一下Unity中实现的单例模式，毕竟没有实际用C++写过单例模式的代码。大概有几种策略：
>
> - （1）对于继承自Monobehavior的类，可以手动挂载/脚本自动挂载（`AddComponent`）在场景中的物体上。在单例类中声明**私有静态变量保证唯一实例。**在`Awake`函数中检查实例是否存在，如果存在则销毁当前对象；若不存在则赋值当前实例，并可以选择调用`DontDestoryOnLoad`保持跨场景的有效；可以设置静态属性`Instance`提供对单例的安全访问。
> - （2）对于非继承于`Monobehavior`的类，只需要正常在`GetInstance`的时候判断是否为空，为空的话`new`出来一份即可。
>
> 额外补充的话，可以提到**单例模式**中的饿汉式和懒汉式。具体可以看这篇：[【C++】C++ 单例模式总结（5种单例实现方法）_单例模式c++实现-CSDN博客](https://blog.csdn.net/unonoi/article/details/121138176)。简要概括一下：
>
> - 懒汉式：系统运行中，实例并不存在，只有当需要使用该实例时，才会去创建并使用实例。这种方式要考虑线程安全（可以使用**互斥锁**）。
> - 饿汉式：系统一运行，就初始化创建实例，当需要时，直接调用即可。这种方式本身就线程安全，没有多线程的线程安全问题。
>
> 补充：懒汉式的互斥锁写法如下（C++）：
>
> ```c++
> static std::shared_ptr<Singleton> singleton = nullptr;
> static std::mutex singletonMutex;
> 
> std::shared_ptr<Singleton> Singleton::getSingleton() {
>     if (singleton == nullptr) { //这个叫双检锁，外层的==nullptr判空是为了防止每次调用getSingleton都加锁，造成性能问题
>         std::unique_lock<std::mutex> lock(singletonMutex);
>         if (singleton == nullptr) {
>             volatile auto temp = std::shared_ptr<Singleton>(new Singleton());
>             singleton = temp;
>         }
>     }
>     return singleton;
> }
> ```
>
> - 之所以使用`shared_ptr`来保存单例而不是`unique_ptr`，**是因为`unique_ptr `单例对象不能被多个线程共享**。`shared_ptr`保存的实例可以被多个线程共享，**具体的在智能指针专题中有额外介绍。**



### （1）如何从构造函数的角度处理单例模式new一个新对象的问题

- 省流版答案：将构造函数设置为私有构造函数（放到private访问修饰符下面即可）。同时，**禁用掉拷贝构造函数和赋值运算符，对外只保留一个`getInstance()`的接口，同时如果是懒汉式在生成实例时需要考虑互斥锁。**

C++单例模式的各种写法可以看这里：[C++ 单例模式的各种坑及最佳实践 - Zijian/TENG - 博客园](https://www.cnblogs.com/tengzijian/p/17473248.html)



### （2）一份C++11 之后的单例模式最佳实践

这个版本利用局部静态变量来实现单例模式。最早由 C++ 大佬、Effective C++ 系列的作者 Scott Meyers 提出，因此也被称为 Meyers’ Singleton。特点是**最简洁，线程安全，且没有额外的指针。**

> "This approach is founded on C++'s guarantee that local static objects are initialized when the object's definition is first encountered during a call to that function." ... "As a bonus, if you never call a function emulating a non-local static object, you never incur the cost of constructing and destructing the object."
> —— Scott Meyers

```c++
class Singleton {
   public:
    static Singleton& getInstance() {
        static Singleton inst;
        return inst;
    }

    Singleton(const Singleton&) = delete;
    Singleton& operator=(const Singleton&) = delete;

   private:
    Singleton() = default;
};
```



# 计算机网络篇

High Level层面过一下计网：[(99+ 封私信 / 82 条消息) 有了 IP 地址，为什么还要用 MAC 地址？ - 知乎](https://www.zhihu.com/question/21546408/answer/2303205686)

首先，关于TCP协议，非常建议看这篇文章先复习一下：[4.1 TCP 三次握手与四次挥手面试题 | 小林coding](https://xiaolincoding.com/network/3_tcp/tcp_interview.html#tcp-基本认识)

这部分内容在Games104中也有所讲解，可以去这里回顾一下：[Voices from Community - T-shirt Style](https://games-1312234642.cos.ap-guangzhou.myqcloud.com/course/GAMES104/GAMES104_Lecture18.pdf)以及[Network Synchronization](https://games-1312234642.cos.ap-guangzhou.myqcloud.com/course/GAMES104/GAMES104_Lecture19.pdf)。目标是照着PPT可以大概说出讲解的内容，忘了的话可以去B站回顾Games104的课程。



## 【1】TCP 三次握手与四次挥手

由于TCP是面向连接的协议，所以TCP在使用前一定会**建立连接**，而建立连接是通过三次握手来进行的。这里还是给出链接：[4.1 TCP 三次握手与四次挥手面试题 | 小林coding](https://xiaolincoding.com/network/3_tcp/tcp_interview.html#tcp-三次握手过程是怎样的)，写的不错。有一些衍生问题，可以回顾，答案都在链接中：

- （1）三次握手的过程是什么样的？
- （2）为什么是三次握手，而不是两次或者四次？
- （3）第一次，第二次，第三次握手丢失的情况，会发生什么？
- （4）TCP四次挥手的过程是什么样的？
- （5）为什么需要四次挥手？可以变成三次么？[4.22 TCP 四次挥手，可以变成三次吗？ | 小林coding](https://xiaolincoding.com/network/3_tcp/tcp_three_fin.html)
- （6）第一、二、三、四次挥手丢失了会发生什么？
- （7）四次挥手的时候，为什么需要TIME_WAIT状态？
- （8）如果已经建立了连接，但是客户端突然出现故障了怎么办？（考察：TCP保活机制）
- （9）如果已经建立了连接，但是服务端的进程崩溃会发生什么？（考察：依旧会发生四次挥手）



## 【2】TCP协议和UDP协议的区别？分别的应用场景？

题目答案来自小林coding：[4.1 TCP 三次握手与四次挥手面试题 | 小林coding](https://xiaolincoding.com/network/3_tcp/tcp_interview.html#udp-和-tcp-有什么区别呢-分别的应用场景是)

这个网站不让复制，复习的时候可以点进去复习，这里整理一些重点内容：

> 以下是 TCP 协议和 UDP 协议的主要区别，以表格形式展示：
>
> | 特性       | TCP (传输控制协议)                          | UDP (用户数据报协议)               |
> | ---------- | ------------------------------------------- | ---------------------------------- |
> | 连接类型   | 面向连接                                    | 无连接                             |
> | 数据可靠性 | 提供可靠的数据传输 (重传机制)               | 不提供可靠性                       |
> | 数据顺序   | 保证数据按顺序到达                          | 不保证数据顺序                     |
> | 流量控制   | 支持流量控制                                | 不支持流量控制                     |
> | 拥塞控制   | 提供拥塞控制                                | 不提供拥塞控制                     |
> | 数据包大小 | 最大 65,535 字节（含头部）                  | 最大 65,507 字节（不含头部）       |
> | 头部开销   | 20 字节                                     | 8 字节                             |
> | 使用场景   | 适用于需要可靠性和顺序的应用 (如 HTTP、FTP) | 适用于实时应用 (如 VoIP、视频会议) |
> | 性能       | 较慢，因建立连接和重传机制                  | 较快，无需连接建立和维护           |
>
> ### 总结
>
> - **TCP**：可靠传输（数据不丢失，顺序一致）、面向连接、流量控制、拥塞控制。适合需要顺序和完整性的场景。
>   - 缺点：延迟较高（重传机制导致），且报文头部开销较大（20字节的头部）
> - **UDP**：不可靠、无连接、适合实时传输，低延迟；
>   - 缺点：需要自行处理丢包、乱序等问题。
>
> 注：TCP 和 UDP 的头部不需要包含 IP 地址，因为该信息已在网络层的 IP 数据包中处理。只需通过端口号来区分不同应用程序的通信，这样既能简化协议设计，又能提高效率。
>
> ## 应用场景举例
>
> - 优先使用TCP：
>
>   - 需要严格可靠性的业务：
>     - 如账号登陆/支付系统
>     - 回合制游戏中，每一步操作的顺序严格保证；
>     - 排行榜/成就同步：数据一致性至关重要
>
>   - 对延迟不敏感的场景：比如游戏内邮件系统、配置表/资源更新。
>
> - 优先使用UDP的场景：
>
>   - 实时性要求高的操作
>     - 比如FPS游戏，MOBA游戏，赛车/格斗游戏。**注意，这里可能是考察的地方，因为UDP不可靠，所以纯用UDP可能会导致丢包乱序问题，需要自行处理，这时就可以说KCP协议了，见下。**
>   - 高频但允许少量丢包的数据：语音聊天、环境特效同步（如天气变化）等。
>
> 现代游戏通常使用混合协议策略，根据数据类型选择最优方案，下面会提到的KCP协议灵活度较高，有性能优势，很多实时游戏会使用KCP作为首选解决方案。



## 【3】（了解）KCP协议

可以参考的链接：[GitHub - skywind3000/kcp: :zap: KCP - A Fast and Reliable ARQ Protocol](https://github.com/skywind3000/kcp)。以及对应的一些解读：[在网络中狂奔：KCP协议 - 知乎](https://zhuanlan.zhihu.com/p/112442341)

原理：

- **基于UDP的可靠传输协议**，通过改进重传策略和拥塞控制，提供比TCP更低的延迟。

核心优化：

- **快速重传：**无需等待超时，通过重复ACK立刻重传丢失包；与TCP相同，都是通过累计确认实现的，比如发送端发送了1，2，3，4，5几个包，然后收到远端的ACK：1，3，4，5，当收到ACK = 3时，KCP知道2被跳过1次，收到ACK = 4时，知道2被跳过了2次，此时可以认为2号丢失，不用等超时，直接重传2号，大大改善了丢包时的传输速度。
- **超时重传**：TCP超时计算是RTOx2，这样连续丢三次包就变成RTOx8了，十分恐怖，而KCP启动快速模式后不x2，只是x1.5（实验证明1.5这个值相对比较好），提高了传输速度。
  - 在 TCP 协议中，RTO 指的是 "Retransmission Timeout"，即重传超时时间。它是用来确定在发送数据后，发送方等待确认（ACK）响应的时间长度。如果在这个时间内没有收到确认，发送方会认为数据包可能丢失，并触发重传机制。

适用场景：**需要可靠传输但无法忍受TCP延迟的场景。**

- 比如《原神》使用了KCP协议，可能用于战斗同步：技能命中判定需要可靠且实时。
- 移动端弱网环境：KCP在网络不够好的情况下表现优于TCP。



## 【4】帧同步和状态同步

参考链接：[【网络同步】浅析帧同步和状态同步 - 知乎](https://zhuanlan.zhihu.com/p/357973435)。这里Games104也有讲，可以在忘了的时候回去复习一下。

> ## 一、帧同步
>
> 《王者荣耀》中采用的主要应该就是帧同步。在初始化的时候，要保证每个客户端的状态都是高度一致的。
>
> ### 1.基本原理
>
> - 帧同步的战斗逻辑在客户端
> - 在帧同步下，通信就比较简单了，服务端只转发操作，不做任何逻辑处理。
> - 客户端按照一定的帧速率（理解为逻辑帧，而不是客户端的渲染帧）去上传当前的操作指令，服务端将操作指令广播给所有客户端，
> - 当客户端收到指令后执行本地代码，如果输入的指令一致，计算的过程一致，那么计算的结果肯定是一致的，这样就能保证所有客户端的同步，这就是帧同步。
>
> ### 2.帧同步缺陷
>
> - 由于帧同步战斗逻辑都在客户端，服务器没有验证，带来的问题就是**外挂**的产生（加速、透视、自动瞄准、数据修改等）
> - 网络条件较差的客户端会影响其他玩家的游戏体验。（优化方案：乐观帧锁定、渲染与逻辑帧分离、客户端预执行、[指令流水线](https://zhida.zhihu.com/search?content_id=167679029&content_type=Article&match_order=1&q=指令流水线&zhida_source=entity)化、操作回滚等）
> - 不同机器浮点数精度问题（解决方案：制作Look up table求解比如$e^x$，或者使用定点数）、容器排序不确定性、RPC时序、随机[数值计算](https://zhida.zhihu.com/search?content_id=167679029&content_type=Article&match_order=1&q=数值计算&zhida_source=entity)不统一
>   - 尽量把游戏中确切的业务需求做到一致性，类似渲染的话要求没那么高。
>
> ### 3.**优化方案**
>
> ![image-20250205193551997](%E9%9D%A2%E7%BB%8F%E5%90%88%E9%9B%86%E2%80%94%E2%80%94%E9%A2%98%E7%9B%AE+%E7%AD%94%E6%A1%88%E7%89%88.assets/image-20250205193551997.png)
>
> 对应[18.网络游戏的架构基础 (Part 2) | GAMES104-现代游戏引擎：从入门到实践_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1HN4y157Zq?spm_id_from=333.788.videopod.sections&vd_source=f0e5ebbc6d14fe7f10f6a52debc41c99) 20分钟左右的地方。
>
> 补充：**乐观帧锁定方法**（跟上面的方法有点像）
>
> 针对传统严格帧锁定算法中网速慢会卡到网速快的问题，实践中线上动作游戏通常用**“定时不等待”的乐观方式，在每次Interval时钟发生时固定将操作广播给所有用户，不依赖具体每个玩家是否有操作更新**：
>
> 1. 单个用户当前键盘上下左右攻击跳跃是否按下用一个32位整数描述，服务端描述一局游戏中最多8玩家的键盘操作为：int player_keyboards[8];
> 2. 服务端每秒钟20-50次向所有客户端发送更新消息（包含所有客户端的操作和递增的帧号）：
> 3. update=（FrameID，player_keyboards）
> 4. 客户端就像播放游戏录像一样不停的播放这些包含每帧所有玩家操作的 update消息。
> 5. 客户端如果没有update数据了，就必须等待，直到有新的数据到来。
> 6. 客户端如果一下子收到很多连续的update，则快进播放。
> 7. 客户端只有按键按下或者放开，就会发送消息给服务端（而不是到每帧开始才采集键盘），消息只包含一个整数。服务端收到以后，改写player_keyboards。
>
> ### 4.帧同步总结
>
> **帧同步的优点：**
>
> - （1）低带宽，仅仅发送指令；
> - （2）很高的开发效率，就好像单人游戏开发一样；
> - （3）精准的动作/碰撞检测（我的理解是因为逻辑是在客户端算的，所以动作和伤害判定都会很准确）；
> - （4）很容易制作观战和回放的功能；
>
> **帧同步的缺点：**
>
> - （1）保持各个客户端的一致性是非常难的问题；
> - （2）难以解决外挂问题，因为帧同步都在客户端算，相当于客户端掌握所有游戏信息，很容易做出那种消除战争迷雾的外挂；
> - （3）如果断线重连的时间过长，中间的状态不太好追赶（因为太多了）；
>
> 
>
> ##  二、状态同步
>
> 大部分的MMORPG，生活类游戏都使用状态同步。
>
> **状态同步顾名思义就是同步各个客户端的状态，保证每一次操作后的状态是一致的。**通过开发服务端程序，把用户的操作作为输入实时上传到服务端，服务端通过计算返回结果给各个客户端，这样的过程就是状态同步。比如说玩家A开了一枪，那么A会给服务器发送自己开枪的报文，服务器确认后会转发给所有其他的客户端，这样其他客户端中的玩家A（叫做Replicated Player）就会同步开枪的状态，从而开枪。同时，如果这时服务器计算出了玩家A这一枪打中的玩家B，那么这个事件也会被同步给所有客户端。**游戏状态的计算是在服务器端的。**
>
> **状态同步的一个优势在于，可以只同步客户端的ROI（Region of Interest）区域。**
>
> ### 1. 基本原理
>
> - **状态同步的战斗逻辑在服务端**
>
> - 在状态同步下，客户端更像是一个服务端数据的表现层
>
> - 一般的流程是
>
> - - 客户端上传操作到服务器，
>   - 服务器收到后计算游戏行为的结果，然后以广播的方式下发游戏中各种状态，
>   - 客户端收到状态后再根据状态显示内容。
>
> - 用示意图表示如下：
>
> - ![img](%E9%9D%A2%E7%BB%8F%E5%90%88%E9%9B%86%E2%80%94%E2%80%94%E9%A2%98%E7%9B%AE+%E7%AD%94%E6%A1%88%E7%89%88.assets/v2-df2089bc7dd3b47107d26df5535fd108_r.jpg)
>
> - 如今的状态同步有：增量同步、RPC（[远程过程调用](https://zhida.zhihu.com/search?content_id=167679029&content_type=Article&match_order=1&q=远程过程调用&zhida_source=entity)）两种同步手段。
>
> - 目前状态同步多用于CS架构，客户端通过RPC向服务器发送指令信息，服务器通过属性同步（增量状态同步）向客户端发送各个对象的状态信息。我们可以才有**预测回滚、延迟补偿、插值等优化方式**。这些在Games104中可以复习到。
>
> - ### 2.2 状态同步缺陷
>
> - - 状态同步做回放系统的话会是个灾难。
>   - 延迟过大、客户端性能浪费、服务端压力大
>   - 对带宽的浪费。对于对象少的游戏，可以用快照保存整个游戏的状态发送，但一旦数量多起来，数量的占用就会直线上升。（优化：增量快照同步，协议同步指定数据）
>
> - 
>
> - ## 帧同步和状态同步对比
>
> - 参考这一篇下半部分：[【网络同步】浅析帧同步和状态同步 - 知乎](https://zhuanlan.zhihu.com/p/357973435)
>
> - - 最大的区别就是**战斗核心逻辑写在哪**？状态同步的战斗逻辑在服务端，帧同步的战斗逻辑在客户端。
>
> - | 属性                                       | 帧同步（LockStep）                                           | 状态同步                                                     |
>   | ------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
>   | 确定性                                     | 严格确定                                                     | 允许小误差，定时纠正误差数据                                 |
>   | 表现与响应速度                             | 传统严格帧锁定要等其他客户端消息全部到达，响应比较慢；乐观帧锁定可以做到本地立刻响应，但是需要回滚的时候，体验就没那么好了 | 一般会做预测，可以做到立刻响应。不做预测的话，响应时间是一个往返时间（RTT） |
>   | 带宽与流量                                 | 带宽随人数增加而增加，不适合MMO                              | 需要发送各种状态数据，带宽占用比较高。可以通过压缩、裁剪、增量等方式优化。人数较少时候不如帧同步省流量 |
>   | 网络延迟适应性                             | 要求较低的延迟。如果延迟较高，所有玩家体验都不好。即使采用乐观帧锁定优化，高延迟下也容易产生卡顿 | 适应性较高，方便做各种插值优化。当然高延迟下，也容易产生位置突变 |
>   | 开发难度                                   | 初期开发减法，框架容易实现，但是后期解决bug和完善系统很困难。比如浮点数、随机数、执行顺序导致计算结果不一致，问题很难排查（排查思路可以是计算各个值的checksum） | 框架比较复杂，客户端服务端各一套代码，每个功能都需要客户端服务端联调。问题定位比较容易。也会出现时序问题 |
>   | 玩家数量                                   | 适合少量的玩家，比如ACT、MOBA                                | 可多可少                                                     |
>   | 跨平台                                     | 不适合跨平台，会有浮点数问题，可以用定点数来将误差控制在一个可接受范围，同时可以定时纠正结果 | 适合。有权威服务器                                           |
>   | 反外挂                                     | P2P架构不适合反外挂，如果引入战斗服务器来校验各个客户端结果，可以解决常见外挂，但是透视和全图视野防不了 | 与服务器加入校验机制，可以起到比较好的反外挂效果。但是一样防不了透视外挂 |
>   | 中途加入和断线重连                         | 比较复杂。可以在断线的时候，通过快捷播放服务器同步的帧数据来快速跟上游戏 | 容易。由于实时记录了各个对象的状态信息，所以重连的时候，直接创建这些对象，并同步信息即可 |
>   | 性能（客户端）                             | 客户端要跑完整逻辑，还要执行渲染逻辑，开销比较大             | 可以灵活优化，客户端跑较少逻辑                               |
>   | 回放（离线）                               | 本身收集了所有玩家的输入信息进行逻辑推进，天然支持回放，且回放文件比较小 | 可以支持回放，但是逻辑比较复杂，需要不断记录状态信息，同时回放时候需要读取合适的时间。回放文件大 |
>   | 回放（实时）（**有些存疑，这条不太用看**） | 比较复杂，客户端需要本地对全场状态进行序列化，才能回到目标时间。播完回放后还需要加速追上实时游戏状态 | 相对容易，可以方便的记录快照信息，并按照录制内容随时播放     |

下图是一些帧同步和状态同步的游戏例子：

![img](%E9%9D%A2%E7%BB%8F%E5%90%88%E9%9B%86%E2%80%94%E2%80%94%E9%A2%98%E7%9B%AE+%E7%AD%94%E6%A1%88%E7%89%88.assets/v2-872213aa1932af45a7d5b39a16ee6f71_r.jpg)



## ==【5】状态同步有哪些优化技术？==

> 这个问题是接在上一个问题之后的，在上一个问题中对帧同步和状态同步有了一个基本的认知，但有一个考察点在于对状态同步更细致一些的考察（关于如何做优化），因此整理在这里。



## ==【6】如何实现可靠UDP？==





# 计算机图形学篇

> 注：计算机图形学的很多知识点在教程里有，这里针对部分问题只给出重要的答题点，具体答案就不完全整理了。

## 【1】渲染管线介绍，分为哪些阶段？

> - 应用阶段：识别出潜在可视的网格实例，并把它们及其材质呈交至图形硬件以供渲染。该阶段包含三大任务：可见性判断、控制着色器参数和渲染状态、提交图元至GPU硬件以供渲染。
>
>   - 空间加速算法、视锥剔除、碰撞检测、动画物理模拟、调用Drawcall；
>
> - 几何阶段：主要负责大部分多边形操作和顶点操作，将三维空间的数据转换为二维空间的数据，可以分为**顶点着色、投影变换、裁剪和屏幕映射阶段**。
>
> - 光栅化阶段：将图元离散化成片段的过程，其任务是找到需要绘制出的所有片段，包括**三角形设定和三角形遍历**阶段；
>
>   - a. 三角形设置(图元装配)，计算出三角形的一些重要数据(如三条边的方程、深度值等)以供三角形遍历阶段使用，这些数据同样可用于各种着色数据的插值。
>
>     b. 三角形遍历，找到哪些像素被三角形所覆盖，并对这些像素的属性值进行插值。通过判断像素的中心采样点是否被三角形覆盖来决定该像素是否要生成片段。通过三角形三个顶点的属性数据，插值得到每个像素的属性值。**此外透视校正插值也在这个阶段执行。**
>
> - 像素着色阶段：**片元着色器像素着色+合并阶段（透明测试、模板测试、深度测试，blend操作等）**



## 【2】OpenGL中的渲染管线介绍

> （注：这个问题将图形渲染管线具体到了某一个图形[API](https://zhida.zhihu.com/search?content_id=183804732&content_type=Article&match_order=1&q=API&zhida_source=entity)，因此涉及到了一些具体概念，但是大体上跟上面描述的图形渲染管线一致）
>
> 【**Reference**】：[你好，三角形 - LearnOpenGL CN (learnopengl-cn.github.io)](https://link.zhihu.com/?target=https%3A//learnopengl-cn.github.io/01%20Getting%20started/04%20Hello%20Triangle/)、[【OpenGL】OpenGL渲染流程详解_Zok93-CSDN博客_opengl渲染](https://link.zhihu.com/?target=https%3A//blog.csdn.net/sinat_20559947/article/details/78886440)
>
> - （1） VBO将数据存储到缓存中，VAO绑定顶点属性关系，然后VBO将缓存数据传给vertex_shader（注：还可以回顾一下IBO/EBO：存放图元对应的顶点索引）；
> - （2）在顶点着色器中进行坐标变换，由mvp矩阵将其转换到裁剪坐标系，以及顶点着色；
> - （3）然后到裁剪和屏幕映射阶段；裁剪掉视锥体外的图元，将当前坐标映射到屏幕坐标；
> - （4）三角形设置阶段（或是图元装配阶段），将顶点着色器的输出数据装配成指定图元的形状；
> - （5） 然后进入光栅化阶段，找到哪些像素被三角形覆盖，以及进行插值计算；
> - （6）然后进入到了fragment_shader，执行光照计算，进行着色；
> - （7） 最后进入到测试混合阶段，包括Alpha测试、模板测试、深度测试等，然后进行混合。



## 【3】**各种测试(缓冲)的含义，相对顺序？**

> - （1）深度测试：略
> - （2）Alpha测试：像素值一般是由[RGBA](https://zhida.zhihu.com/search?content_id=183804732&content_type=Article&match_order=1&q=RGBA&zhida_source=entity)四个分量来表示的，其中的A是alpha，表示的是物体的不透明度。1代表完全不透明，0代表完全透明。可选的 alpha 测试可在深度测试执行前在传入片段上运行。片段的 alpha 值与参考值作某些特定的测试（如等于，大于等），如果片段未能通过测试，它将不再进行进一步的处理。 alpha 测试经常用于不影响深度缓存的全透明片段的处理。简单来说，就是根据物体的透明度来决定是否渲染。
> - （3）模板测试：模板缓冲是用于记录所呈现图元位置的离屏缓存。如果使用了模板缓冲，就相当于在屏幕上有一块模板盖在上面，只有位于这个模板中的图元片段，才会被渲染出来。模板测试就是用片段指定的参考值与模板缓冲中的模板值进行比较，如果达到预设的比较结果，模板测试就通过了，然后用这个参考值更新模板缓冲中的模板值；如果没有达到预设的比较结果，就是没有通过测试，就不更新模板缓冲。简单来说，就是根据物体的位置范围决定是否渲染。
> - （4）裁剪测试（**没用过，可以不主动提这个**）：在裁剪测试中，允许程序员开设一个裁剪框，只有在裁剪框内的片元才会被显示出来，在裁剪框外的片元皆被剔除。裁切测试可以避免当视口比屏幕窗口小时造成的渲染浪费问题。通常情况下，我们会让视口的大小和屏幕空间一样大，此时可以不需要使用到裁切测试。但当两者大小不一样大时，我们需要用到裁切测试来避免其产生的一些问题。如下图所示：
> - ![img](%E9%9D%A2%E7%BB%8F%E5%90%88%E9%9B%86%E2%80%94%E2%80%94%E9%A2%98%E7%9B%AE+%E7%AD%94%E6%A1%88%E7%89%88.assets/v2-52e7f65de9819499d8f5d257e502927f_r.jpg)
>
> 图中的绿色方框表示视口范围，大的黑色方框表示屏幕范围，当视口小于屏幕的时候，如果不用裁剪测试，则会将视口范围外的背景白色也绘制出来，导致渲染浪费，结果也不正确。

**各种测试的相对顺序：裁剪->Alpha->模板->深度**。主要记住**Alpha->模板->深度测试这个顺序**。



## ==【4】各种反走样技术的问题==

> 具体算法的细节在图形学教程中有所整理。这里只给出大致算法。包含MSAA，SSAA，FXAA，TAA，SMAA，还可以提一下Nvidia的超分辨率DLSS系列全家桶。



## ==【5】在渲染中，透明物体的深度测试和深度写入==





# Unity篇

## ==【1】Navigation系统的介绍==



# 场景题目篇

> 这一部分的题目会给出一个业务需求，要求给出分析或者实现。整理一下对应的题目。

## ==【1】设计一个背包系统（写代码）考虑各种情况，如空位置、加物品超上限==



# 算法题目篇

## 【1】给出平面上n个点，求出任意两点组成的直线中斜率最大的两个点。

> 思路看这篇的理论部分即可：[浅谈一类平面点对斜率最值问题_二维坐标平面,斜率最大的两个点-CSDN博客](https://blog.csdn.net/m0_38013346/article/details/80434208)。实现上就是把所有的`x`从小到大排序，斜率最大的点对一定在相邻两个点之间。



## 【2】用队列实现栈

> 思路：需要两个队列，记当前活跃队列为q1，另一个辅助队列为q2
>
> - （1）push操作：直接放入当前的活跃队列q1中即可；
> - （2）pop操作：从当前活跃队列q1中不断拿出元素放入q2，直到q1中只剩下一个元素，pop出去。然后将q1和q2做swap，保证q1是当前活跃队列；**注：pop操作需要判断队列是否为空。**
> - （3）top操作：从当前活跃队列q1中不断拿出元素放入q2，直到q1中只剩下一个元素，这个元素即为top的返回值，在算出来之后入队到q2中，然后swap（q1，q2），保证q1是当前活跃队列；**注：top操作需要判断队列是否为空。**
> - （4）empty（）操作：只需判断q1是否为空即可；

可以做Leetcode的这道题目：[225. 用队列实现栈 - 力扣（LeetCode）](https://leetcode.cn/problems/implement-stack-using-queues/)。这道题目保证pop和top操作时栈不会空，所以就不用特判了。实现的代码如下：

```c++
class MyStack {
public:
    queue<int> q1;
    queue<int> q2;
    MyStack() {}
    
    void push(int x) 
    {
        q1.push(x); //统一都push到q1里
    }
    
    int pop() 
    {
       int size = q1.size();
       for(int i=1;i<size;i++)
       {
            int front = q1.front();
            q1.pop();
            q2.push(front);
       }
       int res = q1.front();
       q1.pop();
       swap(q1,q2);
       return res;
    }
    
    int top()
    {
        int size = q1.size();
        for(int i=1;i<size;i++)
        {
            int front = q1.front();
            q1.pop();
            q2.push(front);
        }
        int res = q1.front();
        q1.pop();
        q2.push(res);
        swap(q1,q2);
        return res;
    }
    
    bool empty() {
        return q1.empty();
    }
};

/**
 * Your MyStack object will be instantiated and called as such:
 * MyStack* obj = new MyStack();
 * obj->push(x);
 * int param_2 = obj->pop();
 * int param_3 = obj->top();
 * bool param_4 = obj->empty();
 */
```



## 【3】用栈实现队列

> 思路：需要两个栈s1，s2。各个算法如下：
>
> - （1）push：此时统一push进第一个栈s1里；
> - （2）pop：如果s2为空，则把s1里的元素依次放入s2当中，然后pop出s2最上面的元素（前提合法，即s2不为空）；
>   - 如果s2不为空，则直接pop出s2的最上面元素；
> - （3）peek操作：与pop类似，只不过不需要pop。如果s2为空，则把s1里的元素依次放入s2当中，返回s2的top元素；s2不为空的情况直接返回s2的最上面元素；
> - （4）empty操作：判断是否s1为空且s2为空；
>
> 注：理论上每一步操作也要用代码保证合法性，这个也要看面试时的需求。

可以做一下Leetcode的这道题目：[232. 用栈实现队列 - 力扣（LeetCode）](https://leetcode.cn/problems/implement-queue-using-stacks/description/)。这里给出AC代码：

```c++
class MyQueue {
public:
    stack<int> s1;
    stack<int> s2;
    MyQueue() {}
    
    void push(int x) {
        s1.push(x);
    }
    
    int pop() {
        int top = -1;
        if(!s2.empty())
        {
            top = s2.top();  s2.pop();
            return top;
        }
        while(!s1.empty())
        {
            top = s1.top(); s1.pop();
            s2.push(top);
        }
        if(!s2.empty())
        {
            top = s2.top(); s2.pop();
        }
        return top;
    }
    
    int peek() {
        int top = -1;
        if(!s2.empty())
        { 
            return s2.top();
        }
        while(!s1.empty())
        {
            top = s1.top(); s1.pop();
            s2.push(top);
        }
        if(!s2.empty()) top = s2.top();
        return top;
    }
    
    bool empty() {
        return s1.empty() && s2.empty();
    }
};

/**
 * Your MyQueue object will be instantiated and called as such:
 * MyQueue* obj = new MyQueue();
 * obj->push(x);
 * int param_2 = obj->pop();
 * int param_3 = obj->peek();
 * bool param_4 = obj->empty();
 */
```



## ==【4】最小覆盖子串==

https://leetcode.cn/problems/M1oyTv/



## ==【5】树的序列化和反序列化==

[297. 二叉树的序列化与反序列化 - 力扣（LeetCode）](https://leetcode.cn/problems/serialize-and-deserialize-binary-tree/description/)。这道题目的题解参考Leetcode官方题解的解法1，**需要对字符串的接口足够熟悉。**





##  ==【6】最大频率栈==

[895. 最大频率栈 - 力扣（LeetCode）](https://leetcode.cn/problems/maximum-frequency-stack/description/)



## ==【7】最长无重复子串==

[LCR 016. 无重复字符的最长子串 - 力扣（LeetCode）](https://leetcode.cn/problems/wtcaE1/description/)



## 【8】归并排序

在`排序算法`对应的专题md中有介绍，这里以[912. 排序数组 - 力扣（LeetCode）](https://leetcode.cn/problems/sort-an-array/description/)为例直接给出题解：

```c++
class Solution {
public:
    void mergeSort(vector<int>& nums, vector<int>& tmp, int l, int r)
    {
        if(l>=r) return;
        int mid = (l+r)>>1;
        //归
        mergeSort(nums, tmp, l, mid);
        mergeSort(nums, tmp, mid+1, r);
        //并
        int i=l, j=mid+1, k=0;
        while(i<=mid&&j<=r)
        {
            if(nums[i]<=nums[j]) tmp[k++]=nums[i++];
            else tmp[k++]=nums[j++];
        }
        while(i<=mid) tmp[k++]=nums[i++];
        while(j<=r) tmp[k++]=nums[j++];
        for(int i=l, k=0;i<=r;i++, k++)
            nums[i] = tmp[k];

    }
    vector<int> sortArray(vector<int>& nums) {
        //归并排序
        int n = nums.size();
        vector<int> tmp(n);
        mergeSort(nums, tmp, 0, n-1);
        return nums;
    }
};
```



# 其他未整理问题

【1】平常玩啥游戏？解释一下你玩的游戏中的网络协议。

【2】手撕（没看懂啥意思，别的地方看到了再整理进算法篇里吧）：1.图片求内存 2.数字逻辑题 3.扑克牌问题

【3】动态规划实际上的应用：在游戏开发中，那种走格子的小游戏可能会用动规吧hhh，多做点题就知道动规的应用场景了。



# 面经链接合集

【1】[游戏客户端秋招面经总结_牛客网](https://www.nowcoder.com/discuss/702122998706262016?sourceSSR=search)

【2】[腾讯IEG游戏客户端一面二面面经_牛客网](https://www.nowcoder.com/discuss/603563266169733120?sourceSSR=search)