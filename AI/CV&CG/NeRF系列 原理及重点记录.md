# NeRF系列 原理及重点记录

参考之前的NeRF相关的笔记，以及这个视频：https://www.youtube.com/watch?v=CRlN-cYFxTk&t=420s

NeRF的官方主页：https://www.matthewtancik.com/nerf，先过一下Demo。



# 关于Volume Rendering的介绍

https://www.youtube.com/watch?v=1PqvwOjnKJw

公式的推导可以看这篇：https://yconquesty.github.io/blog/ml/nerf/nerf_rendering.html#the-rendering-formula

> 对这篇的公式推导有一些补充：
>
> - $p_{hit}(z)$的公式推导有误，经过推导应该是多了一个负号。

https://zhuanlan.zhihu.com/p/574351707



# NeRF的Related Work介绍

> 以下是NeRF论文Related Work部分的总结表格，方便对比不同方法的优势和劣势：
>
> ---
>
> ### **神经隐式表示（Neural Implicit Representations）**
> | **方法**             | **代表工作**  | **核心思想**                                               | **优势**                 | **劣势**                                 | **NeRF改进点**                                    |
> | -------------------- | ------------- | ---------------------------------------------------------- | ------------------------ | ---------------------------------------- | ------------------------------------------------- |
> | SDF/Occupancy Fields | [11,15,27,32] | 用MLP将3D坐标映射到符号距离（SDF）或占据概率（Occupancy）  | 连续表示，无分辨率限制   | 依赖真实3D监督（需合成数据集如ShapeNet） | 无需3D监督，仅用2D图像优化                        |
> | 可微分渲染优化       | [29,42]       | 通过可微分渲染从2D图像优化隐式3D表示（如3D纹理场或特征场） | 无需3D监督，支持复杂几何 | 优化困难，几何复杂度低，渲染结果模糊     | 引入5D辐射场（3D位置+2D视角），提升几何和外观细节 |
>
> ---
>
> ### **传统离散表示（Traditional Discrete Representations）**
> #### **1. 基于网格（Mesh-Based）**
> | **方法**              | **代表工作**       | **核心思想**                     | **优势**             | **劣势**                                                     | **NeRF改进点**                         |
> | --------------------- | ------------------ | -------------------------------- | -------------------- | ------------------------------------------------------------ | -------------------------------------- |
> | 可微分光栅化/路径追踪 | [4,10,22,23,25,30] | 优化网格顶点和纹理以匹配输入图像 | 显式几何，物理可解释 | 需要模板网格初始化，优化易陷入局部最优，拓扑固定（个人补充：一种比较经典的该方法可能是DMTET） | 完全隐式表示，无需初始化模板，几何灵活 |
>
> #### **2. 基于体素（Voxel-Based）**
> | **方法**      | **代表工作**       | **核心思想**                  | **优势**               | **劣势**                                   | **NeRF改进点**                                |
> | ------------- | ------------------ | ----------------------------- | ---------------------- | ------------------------------------------ | --------------------------------------------- |
> | 体素着色      | [19,40,45]         | 直接对体素网格着色            | 简单易实现             | 存储和计算成本高，分辨率受限               | 用MLP参数编码连续体积，存储成本低，分辨率无限 |
> | 神经网络+体素 | [9,13,24,41,43,52] | 结合CNN和体素网格提升表示能力 | 部分缓解体素离散性问题 | 仍受限于体素分辨率，高分辨率场景需大量存储 | 完全连续表示，无需离散采样                    |
>
> ---
>
> ### **视图合成与图像渲染（View Synthesis & Image-Based Rendering）**
> | **方法**       | **代表工作** | **核心思想**                            | **优势**                 | **劣势**                         | **NeRF改进点**                       |
> | -------------- | ------------ | --------------------------------------- | ------------------------ | -------------------------------- | ------------------------------------ |
> | 光场插值       | [5,7,21]     | 通过密集视角采样插值生成新视图          | 高保真渲染（密集采样时） | 依赖密集视角输入，稀疏视角效果差 | 仅需稀疏输入视角，通过隐式辐射场插值 |
> | 基于图像的渲染 | [2,8,48,49]  | 从图像预测几何和外观参数（如网格+材质） | 显式控制场景属性         | 优化困难，复杂几何易出现伪影     | 隐式表示复杂几何和材质，减少伪影     |
>
> ---
>
> ### **核心对比总结**
> 1. **神经隐式表示**：  
>    - 优势：连续、无分辨率限制、存储高效。  
>    - 劣势：早期方法依赖3D监督，可微分渲染优化困难，几何复杂度低。  
>    - **NeRF突破**：引入**5D辐射场**（位置+视角），结合体渲染（Volume Rendering），实现高保真渲染。
>
> 2. **传统离散表示**：  
>    - 优势：显式几何（如网格）、物理可解释。  
>    - 劣势：存储和计算成本高，分辨率受限，优化困难。  
>    - **NeRF改进**：用MLP参数编码连续体积，避免离散采样，存储成本极低。
>
> 3. **视图合成**：  
>    - **NeRF优势**：仅需稀疏输入视角，隐式插值复杂光场，渲染质量显著优于传统光场和体素方法。
>
> ---
>
> ### **复习要点**
> - **NeRF核心创新**：  
>   1. 将场景编码为**连续5D辐射场**（3D位置 + 2D视角方向）。  
>   2. 通过**体渲染积分**（Volume Rendering）实现可微分渲染。  
>   3. **无需3D监督**，仅用2D图像优化，支持复杂几何和视角相关效果（如镜面反射）。  
>
> - **关键对比结论**：  
>   NeRF在渲染质量、存储效率和几何灵活性上全面超越传统方法，成为首个基于神经隐式表示实现照片级真实感渲染的技术。



## 二、NeRF的网络结构

> 以下是NeRF网络结构的详细解读及示意图：
>
> ---
>
> ### **NeRF网络结构解析**
> NeRF的核心是一个多层感知机（MLP），输入为3D坐标 **x** 和视角方向 **d**，输出为体积密度 **σ** 和视角相关的RGB颜色 **c**。其设计分为两个阶段，分别处理空间位置和视角依赖的外观。
>
> #### **1. 第一阶段：处理3D坐标（生成体积密度和中间特征）**
> - **输入**：3D坐标 **x** (经过位置编码后的高维向量)。
> - **网络层**：
>   - 8个全连接层（FC Layers），每层256通道，激活函数为ReLU。
>   - 第1~7层仅处理坐标信息。
>   - 第8层输出：
>     - **体积密度 σ**（直接通过线性层输出，无激活函数）。
>     - **256维中间特征向量**（用于后续颜色预测）。
> - **作用**：学习3D空间中的几何形状（σ表示某点的“不透明度”）和中间特征。
>
> #### **2. 第二阶段：处理视角方向（生成颜色）**
> - **输入**：
>   - 第一阶段输出的256维特征向量。
>   - 视角方向 **d**（经过位置编码后的高维向量）。
> - **网络层**：
>   - 将特征向量与视角方向拼接（Concatenation）。
>   - 1个全连接层（128通道，ReLU激活）。
>   - 输出层：3通道RGB颜色 **c**（通过Sigmoid约束到[0,1]范围）。
> - **作用**：学习视角相关的外观（如镜面反射、高光）。
>
> #### **关键设计细节**
> 1. **位置编码（Positional Encoding）**：
>    - 输入坐标 **x** 和视角方向 **d** 会先通过高频位置编码映射到高维空间，帮助MLP捕捉高频细节。
>    - 例如：坐标 **x** 编码为$  \gamma(x) = [\sin(2^0 x), \cos(2^0 x), ..., \sin(2^{L-1} x), \cos(2^{L-1} x)] $，其中 \( L \) 是编码阶数（论文中 \( L=10 \) 用于坐标，\( L=4 \) 用于方向）。
>
> 2. **分阶段处理**：
>    - 体积密度 **σ** 仅依赖位置，颜色 **c** 同时依赖位置和视角方向，因此网络分两阶段计算。
>
> ---
>
> ### **网络结构示意图**
> ```plaintext
> 输入: 3D坐标x (位置编码后)                输入: 视角方向d (位置编码后)
>        │                                      │
>        ▼                                      ▼
> ┌───────────────────┐                   ┌───────────────┐
> │ FC 256 (ReLU)     │                   │ Concatenate   │
> ├───────────────────┤                   └───────┬───────┘
> │ FC 256 (ReLU)     │                           │
> ├───────────────────┤                           ▼
> │       ...         │                  ┌───────────────────┐
> ├───────────────────┤                  │ FC 128 (ReLU)    │
> │ FC 256 (ReLU)     │                  ├───────────────────┤
> └───────┬───────────┘                  │ FC 3 (Sigmoid)   │
>         │                               └─────────┬─────────┘
>         ▼                                       ▼
> 体积密度 σ (1通道)                         RGB颜色 c (3通道)
> ```
>
> ---
>
> ### **代码简化示例（PyTorch风格）**
> ```python
> import torch
> import torch.nn as nn
> 
> class NeRF(nn.Module):
>     def __init__(self):
>         super().__init__()
>         # 第一阶段：处理坐标x
>         self.xyz_layers = nn.Sequential(
>             nn.Linear(3 + 3*2*10, 256),  # 输入为位置编码后的x（维度3+60=63）
>             nn.ReLU(),
>             *[nn.Sequential(nn.Linear(256, 256), nn.ReLU()) for _ in range(7)]
>         )
>         self.sigma_layer = nn.Linear(256, 1)  # 输出σ
>         
>         # 第二阶段：处理方向d和中间特征
>         self.rgb_layers = nn.Sequential(
>             nn.Linear(256 + 3 + 3*2*4, 128),  # 拼接特征和方向编码后的d（维度3+24=27）
>             nn.ReLU(),
>             nn.Linear(128, 3),
>             nn.Sigmoid()  # 颜色约束到[0,1]
>         )
>     
>     def forward(self, x, d):
>         # 输入x: [N, 63], d: [N, 27]
>         features = self.xyz_layers(x)
>         sigma = self.sigma_layer(features)
>         
>         # 拼接特征和方向编码后的d
>         rgb_input = torch.cat([features, d], dim=-1)
>         rgb = self.rgb_layers(rgb_input)
>         return sigma, rgb
> ```
>
> ---
>
> ### **核心优势**
> 1. **分离几何与外观**：
>    - 体积密度 **σ** 仅由坐标决定，颜色 **c** 由坐标和视角共同决定，符合物理规律。
> 2. **高频细节捕捉**：
>    - 位置编码使MLP能学习高频几何和材质变化。
> 3. **轻量高效**：
>    - 全连接网络参数量小（~1MB），适合优化复杂场景。
>
> ---
>
> ### **复习要点**
> - **输入输出**：坐标→σ（几何），坐标+方向→颜色（外观）。
> - **位置编码**：解决MLP难以学习高频信号的问题。
> - **分阶段设计**：几何和外观解耦，提升渲染真实性。