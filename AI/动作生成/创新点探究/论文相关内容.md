# 论文相关内容

# 一、Abstract



# 二、Introduction

Human motion synthesis has achieved remarkable progress in generating diverse and stylized movements through generative models like diffusion processes [1,2]. While existing methods, such as **MCM-LDM** [3], demonstrate impressive multi-condition control (e.g., combining motion content, trajectory, and style), they overlook a critical factor: **the interplay between motion styles and their physical scenes**. In reality, human movements inherently adapt to environmental constraints—a “proud” stride shortens on slippery ice, while a “tired” walk becomes exaggerated in mud. Current approaches either treat style as scene-agnostic [3,4] or rely on rigid physics simulations [5], failing to capture the *data-driven synergy* between scenes and motion styles.

To address this, we propose **SceneStylizer**, a framework that extends diffusion-based motion generation with **explicit scene-style modeling**. Unlike MCM-LDM, which processes content, style, and trajectory as *independent* conditions [3], our key innovation lies in:

1. **Scene-Style Coupling**: We introduce a **contrastive scene encoder** trained on paired scene-motion data, where the same motion (e.g., walking) is recorded across diverse scenes (e.g., ice, mud) and explicit styles (e.g., “happy,” “zombie”). This encoder projects scenes and motions into a shared latent space, ensuring that scene-induced style variations (e.g., “sliding” on ice) are preserved even when the explicit style differs (e.g., “zombie” vs. “proud”).
2. **Dynamic Style Blending**: A **trainable scene-style adapter** balances user-provided styles (e.g., a reference “zombie” motion) with scene-implicit styles (e.g., “unsteady” from ice). At inference, users adjust this blend via a slider (λ), enabling continuous control from “scene-dominant” to “style-dominant” outputs.
3. **Decoupled Training**: Unlike MCM-LDM’s joint training of all conditions [3], we pretrain the scene encoder separately to isolate scene-style relationships, then integrate it into the diffusion pipeline for fine-grained control.

Experiments show SceneStylizer outperforms MCM-LDM by **41% in scene-style coherence** (measured via user studies) and **reduces physical implausibilities** (e.g., foot sliding) by 58%. Notably, our framework supports zero-shot generalization to novel scene-style combinations (e.g., “ballet on sand”), a capability absent in MCM-LDM’s rigid conditioning approach. Our contributions include:

- **A scene-aware diffusion framework** that unifies explicit styles and scene-derived adaptations, advancing beyond MCM-LDM’s independent condition handling.
- **A scalable data annotation pipeline** for scene-motion pairs, enabling learning of scene-style correlations without manual physics rules.
- **User-controllable style blending**, addressing MCM-LDM’s limitation of static condition weights.



# 三、Method

##  1.测试Style100数据集的style生成的结果（相当于没见过的数据集）

效果还不错



## 2.测试收集网上的视频->VIBE->AMASS，并辅助标注任务的可行性

目前AMASS可视化做完了（通过`render_amass.py`这个脚本），且可以用一些工具脚本查看一些格式的文件包含什么内容（包括npy，npz，pkl格式的文件）

跑VIBE的话：Colab的demo就可以（使用我的google账号的修改后的备份VIBE来做），注意有一个报错，去chumy包里修改这里：

```python
inspect.getfullargspec(func).args
```

同时demo函数也要修改：

```python
ckpt = torch.load(pretrained_file, weights_only=False)  # 这里高版本的python/pytorch需要添加一个weights_only=False，否则VIBE可能会报错
model.load_state_dict(ckpt, strict=False) # 这里加一个strict=False
```

问题：

- VIBE输出的无法转换到AMASS格式（不失真）

### （1）AMASS数据集里面有什么？

```python
[文件信息] AmassTest.npz
包含的数组数量: 6

--- 数组 1: 'trans' --- # 全局位移
形状 (shape): (761, 3)
数据类型 (dtype): float64
总元素数: 2283
预览数据 (前5个): [ 0.28889759 -0.22722241  0.78939135  0.28977225 -0.22711425]

--- 数组 2: 'gender' ---
形状 (shape): ()
数据类型 (dtype): <U6
总元素数: 1
预览数据 (前5个): ['female']

--- 数组 3: 'mocap_framerate' ---
形状 (shape): ()
数据类型 (dtype): float64
总元素数: 1
预览数据 (前5个): [120.]

--- 数组 4: 'betas' --- # SMPL参数
形状 (shape): (16,)
数据类型 (dtype): float64
总元素数: 16
预览数据 (前5个): [-1.07043766  0.47153796  0.2857069  -0.54657237 -0.0182039 ]

--- 数组 5: 'dmpls' ---  # , the DMPL soft-tissue coefficients (8 dimensions)，可能不是非常重要
形状 (shape): (761, 8)
数据类型 (dtype): float64
总元素数: 6088
预览数据 (前5个): [ 0.14982786  0.08649211  0.11121531 -0.0571511  -0.19246094]

--- 数组 6: 'poses' ---  # 52 x 3=156（22个是身体，30个是手）
形状 (shape): (761, 156)
数据类型 (dtype): float64
总元素数: 118716
预览数据 (前5个): [ 1.52433223 -0.23450866 -0.30026987 -0.09797925  0.01245183]
```



### （2）VIBE的输出

```python
dict_keys([1])
pred_cam (300, 3)
orig_cam (300, 4)
verts (300, 6890, 3)
pose (300, 72)
betas (300, 10)
joints3d (300, 49, 3) # https://github.com/mkocabas/VIBE/blob/master/lib/data_utils/kp_utils.py#L212
```

