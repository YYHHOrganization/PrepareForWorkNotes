# 可以参考借鉴的论文模块

> 如果有需要的话，再去细看。==暂时就记录参考的一大堆文章中的创新点，可以用于我们的工作中去的。==



# 一、双人交互+IK

## 1.InterGen: Diffusion-based Multi-human Motion Generation under Complex Interactions

https://github.com/tr3e/InterGen?tab=readme-ov-file

> ### 摘要总结：
> 这篇论文提出了**InterGen**，一种基于扩散模型的方法，用于生成高质量的双人交互动作，仅需文本引导即可定制。主要贡献包括：
> 1. **数据集**：构建了多模态数据集**InterHuman**，包含约1.07亿帧的双人交互动作数据，附带精确的骨骼运动和23,337条自然语言描述。
> 2. **算法设计**：
>    - 针对双人交互场景优化了运动扩散模型，提出**两个协作的Transformer去噪器**，通过权重共享和互注意力机制连接两角色的去噪过程。
>    - 提出**新颖的运动表示方法**，显式建模两角色在世界坐标系中的全局关系。
>    - 引入**两种空间关系正则化项**及对应的阻尼训练方案，增强模型对空间关系的建模能力。
> 3. **效果**：实验表明InterGen生成的交互动作比现有方法更多样、逼真，并支持多种下游应用。
>
> ### 是否了解这篇文章：
> 了解。这篇论文的核心创新点在于：
> 1. **多模态交互数据集**（InterHuman）：填补了双人交互动作数据的大规模标注空白。
> 2. **对称协作去噪架构**：通过权重共享的Transformer和互注意力机制，解决交互动作中角色对称性的建模难题。
> 3. **全局运动表示与空间正则化**：显式编码双人空间关系，结合阻尼训练提升稳定性。
>
> 该方法首次将扩散模型扩展到可控的双人交互生成，突破了传统单人生成框架的限制。

![image-20250512160702071](./assets/image-20250512160702071.png)

这篇文章的Method有解决下面几个问题：

- （1）多人交互的话，动作信息如何编码进去？==其实相当于HumanML3D只包含单人的，如果要做多人可以额外提供什么信息？==可以考虑在世界空间下做，然后用IK来做约束。参考本篇论文的思路。
- （2）Human Interaction Diffusion的步骤：==这篇文章对Diffusion的描述比较有意思，可以借鉴写法，不是那种最传统的公式介绍。==
  - ==Interaction Diffusion部分==：有需要可以看。



### （1）动作信息编码

> ### **1. 问题背景**
>
> - **Com-MDM (Shafir et al., 2023)** 的局限性：
>   传统运动表示（如基于局部坐标系的方法）会丢失**全局空间关系**（例如两人交互时的相对位置和朝向）。Com-MDM尝试通过预测两人初始的相对旋转（rotation）和平移（translation）来缓解这一问题，但未在运动状态中持续建模这些信息。
>
> 而本文编码了如下的动作信息：
>
> ---
>
> ### **1. 运动状态表示（公式1）**
> 运动状态 \( x^i \) 被定义为以下分量的拼接向量：  
> $$
> x^i = [r^a, r^x, r^z, r^y, j^p, j^v, j^r, c^f, r^h, t^h]
> $$
>
> 各分量的具体含义：  
>
> ![image-20250512163819537](./assets/image-20250512163819537.png)
>
> ![image-20250512164034573](./assets/image-20250512164034573.png)
>
> 刚才的是canonical（标准化的）的表达方式，以下介绍原论文中提到的non-canonical的表达方式：
>
> 这两段文字描述了一项关于**多人运动表示方法**的研究，核心是**传统方法（Canonical Representation）的缺陷**和**新提出的非规范表示（Non-Canonical Representation）的解决方案**。以下是分点解析：
>
> ---
>
> ### **1. 传统方法的缺陷**
> #### **问题：累积漂移（Drift）**
> - **原因**：  
>   ==传统方法（Canonical Representation）通过积分**局部关节速度**来计算全局位置。由于运动捕捉数据中的速度测量存在噪声，积分会导致误差累积，产生**指数级增长的轨迹漂移**（随时间推移，位置误差无限增大）。==
>   - 引用：Von Marcard et al. (2017) 已证明这一问题。
>
> #### **影响场景**：
> - **单人短序列运动合成**：  
>   漂移影响较小，因为只需关注局部动作的合理性（如走路、跑步），无需精确全局位置。  
> - **多人运动合成**：  
>   漂移是灾难性的！因为多人交互（如舞蹈、握手）依赖**个体间精确的空间关系**（距离、朝向）。漂移会导致人物位置错乱，破坏交互真实性。
>
> ---
>
> ### **2. 新方法：非规范表示**
> #### **解决方案**  
> 直接使用**世界坐标系下的绝对运动参数**，避免积分过程。  
> - **关键改进**：  
>   - ==不再将关节位置/速度转换到局部根坐标系（Root Frame），而是**直接保留在世界坐标系（World Frame）**。==
>   - 通过**逆向运动学（IK）**从根关节位置反推全局旋转，避免漂移。
>
> #### **数学表示（公式2）**  
> 运动状态 $x^i$定义为：  
> $$
> x^i = [j_g^p, j_g^v, j^r, c^f]
> $$
> ![image-20250512165334004](./assets/image-20250512165334004.png)
>
> #### **优势**  
>
> 1. **消除漂移**：直接使用世界坐标，无需积分噪声速度。  
> 2. **保持空间关系**：多人交互时，个体间的距离/朝向精确无误。  
> 3. **兼容性**：仍保留局部旋转$j^r$以支持动作细节生成。
>
> ---
>
> ### **3. 总结对比**
> | **维度**     | **传统方法（Canonical）** | **新方法（Non-Canonical）**               |
> | ------------ | ------------------------- | ----------------------------------------- |
> | **坐标系**   | 局部根坐标系              | 世界坐标系 + 局部根旋转                   |
> | **漂移问题** | 严重（积分噪声速度）      | 无（直接使用绝对坐标）                    |
> | **适用场景** | 单人短序列                | 多人长序列交互                            |
> | **计算方式** | 需积分速度推算位置        | ==直接读取世界坐标 + IK逆解==(也是种思路) |
>
> ---
>
> ### **4. 研究意义**
> - **多人运动合成**：为舞蹈、体育、协作任务等提供高保真运动生成基础。  
> - **技术延伸**：可结合扩散模型或GAN，生成文本/条件驱动的复杂交互动作。  
> - **数据友好性**：适用于现有运动捕捉数据集（如AMASS、HumanML3D）的预处理。
>

