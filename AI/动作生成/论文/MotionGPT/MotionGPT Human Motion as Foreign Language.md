##### MotionGPT: Human Motion as Foreign Language

最后更新 2023/09/22 开源

项目地址：https://motion-gpt.github.io/

github地址：https://github.com/OpenMotionLab/MotionGPT	

有demo 过期了

[NeurIPS 2023](https://nips.cc/)

输入：文字



尽管预训练大语言模型不断进步，但如何构建一个统一模型来处理语言与其他多模态数据（如动作）的探索仍充满挑战且尚未触及。幸运的是，人类动作与语言存在语义耦合性，常被视为一种肢体语言。通过将语言数据与大规模动作模型融合，能够实现动作-语言预训练，从而提升动作相关任务的性能。受此启发，我们提出MotionGPT——一个统一、通用且用户友好的动作-语言模型，可处理多种动作相关任务。具体而言，我们采用离散向量量化技术**将人体动作转化为动作标记（motion tokens）**，类似于文本词汇的生成过程。基于这一"动作词库"，我们以统一方式对动作和文本进行语言建模，将人体动作视为一种特殊语言。此外，受提示学习启发，我们使用混合的动作-语言数据对MotionGPT进行预训练，并在基于提示的问答任务上进行微调。大量实验表明，MotionGPT在文本驱动动作生成、动作描述生成、动作预测和动作补全等多个任务上达到了最先进的性能。

关键创新点：
1. 多模态统一建模：首次将人体动作与语言在离散符号空间进行对齐，建立"动作-文本"联合语义空间
2. 灵活的任务适配：通过提示工程实现零样本/少样本学习，支持开放域的动作生成与理解
3. 高效表示学习：采用VQ-VAE将连续动作序列离散化为符号序列，继承语言模型的生成优势

该工作为多模态具身智能的发展提供了新思路，未来可延伸至机器人控制、虚拟人交互等应用场景。

![MotionGPT pipeline](https://motion-gpt.github.io//_next/static/media/pipeline.d5fe01e6.png)